{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble for one video\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_model = torch.load('E:/ASL_Data/data/joint_model/sign_joint_final-249_t1-76_t5-95.pt')\n",
    "joint_motion_model = torch.load('E:/ASL_Data/data/joint_model/sign_joint_motion_final-249_t1-48_t5-85.pt')\n",
    "bone_model = torch.load('E:/ASL_Data/data/joint_model/sign_bone_final-249_t1-74_t5-95.pt')\n",
    "bone_motion_model = torch.load('E:/ASL_Data/data/joint_model/sign_bone_motion_final-249_t1-29_t5-69.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are running scripts in different directories, we will need to change the cwd to the directory of the script\n",
    "# But we will need to change it back to the original directory after we are done\n",
    "# This is the original directory\n",
    "original_cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code block to return to the original directory if a crash changes it\n",
    "# (or just rerun everything)\n",
    "os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_0055.mp4\n"
     ]
    }
   ],
   "source": [
    "# The purpose of this notebook is extracting the needed info from the video (bones, joints, frames, etc.)\n",
    "# It will save this info in the same directory as the video\n",
    "path_to_video = 'E:/ASL_Data/testing/video/v1'\n",
    "#open path and get all files\n",
    "os.chdir(path_to_video)\n",
    "file_name = os.listdir()[0]\n",
    "print(file_name)\n",
    "os.chdir(original_cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen npy files for GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): NoneBlock()\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): NoneBlock()\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): NoneBlock()\n",
      ")\n",
      "FUSE LAYERS\n",
      "ModuleList(\n",
      "  (0): NoneBlock()\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "  )\n",
      ")\n",
      "Length of paths: 58\n",
      "paths:  ['E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0001.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0002.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0003.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0004.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0005.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0006.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0007.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0008.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0009.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0010.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0011.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0012.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0013.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0014.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0015.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0016.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0017.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0018.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0019.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0020.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0021.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0022.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0023.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0024.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0025.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0026.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0027.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0028.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0029.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0030.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0031.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0032.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0033.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0034.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0035.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0036.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0037.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0038.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0039.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0040.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0041.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0042.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0043.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0044.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0045.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0046.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0047.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0048.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0049.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0050.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0051.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0052.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0053.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0054.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0055.jpg', 'E:/ASL_Data/testing/video\\\\frames\\\\E_0055\\\\0056.jpg', 'E:/ASL_Data/testing/video\\\\npy\\\\E_0055.mp4.npy', 'E:/ASL_Data/testing/video\\\\v1\\\\E_0055.mp4']\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/E_0055.mp4.npy\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/E_0055.mp4.npy.npy\n",
      "Frame width: 0\n",
      "Frame height: 0\n",
      "E:/ASL_Data/testing/video\\npy\\E_0055.mp4.npy\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0056.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0056.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0055.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0055.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0054.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0054.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0053.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0053.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0052.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0052.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0051.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0051.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0050.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0050.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0049.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0049.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0048.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0048.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0047.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0047.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0046.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0046.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0045.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0045.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0044.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0044.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0043.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0043.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0042.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0042.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0041.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0041.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0040.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0040.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0039.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0039.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0038.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0038.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0037.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0037.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0036.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0036.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0035.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0035.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0034.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0034.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0033.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0033.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0032.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0032.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0031.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0031.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0030.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0030.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0029.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0029.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0028.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0028.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0027.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0027.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0026.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0026.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0025.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0025.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0024.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0024.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0023.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0023.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0022.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0022.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0021.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0021.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0020.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0020.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0019.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0019.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0018.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0018.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0017.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0017.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0016.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0016.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0015.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0015.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0014.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0014.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0013.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0013.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0012.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0012.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0011.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0011.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0010.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0010.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0009.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0009.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0008.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0008.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0007.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0007.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0006.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0006.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0005.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0005.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0004.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0004.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0003.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0003.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0002.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0002.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n",
      "Setting output to: E:/ASL_Data/testing/video/npy/0001.jpg.npy\n",
      "Frame width: 960\n",
      "Frame height: 960\n",
      "E:/ASL_Data/testing/video\\frames\\E_0055\\0001.jpg\n",
      "0\n",
      "torch.Size([2, 3, 640, 640])\n",
      "torch.Size([2, 3, 480, 480])\n",
      "(133, 3)\n",
      "1\n",
      "Ignoring empty camera frame.\n"
     ]
    }
   ],
   "source": [
    "# First extract .npy file from video using demo.py\n",
    "# NOTE: The directories must be changed in demo.py for now, might need to change that\n",
    "path_to_demo = \"../DataPreparation/wholepose\"\n",
    "os.chdir(path_to_demo)\n",
    "exec(open('demo.py').read())\n",
    "os.chdir(original_cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/ASL_Data/testing/video/v1\\E_0055.mp4\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0001.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0002.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0003.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0004.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0005.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0006.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0007.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0008.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0009.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0010.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0011.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0012.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0013.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0014.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0015.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0016.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0017.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0018.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0019.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0020.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0021.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0022.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0023.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0024.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0025.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0026.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0027.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0028.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0029.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0030.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0031.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0032.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0033.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0034.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0035.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0036.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0037.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0038.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0039.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0040.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0041.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0042.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0043.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0044.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0045.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0046.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0047.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0048.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0049.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0050.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0051.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0052.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0053.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0054.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0055.jpg\n",
      "E:/ASL_Data/testing/video/frames\\E_0055\\0056.jpg\n"
     ]
    }
   ],
   "source": [
    "# Next we will use the .npy file to extract the frames of the video\n",
    "# NOTE: The directories must be changed in gen_frames.py for now, might need to change that\n",
    "path_to_gen_frames = \"../DataPreparation\"\n",
    "os.chdir(path_to_gen_frames)\n",
    "exec(open('gen_frames.py').read())\n",
    "os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gen pt files for TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./wholepose_features_extraction.py --video_path E:/ASL_Data/testing/video/v1 --feature_path E:/ASL_Data/testing/video/pt/v1.pt --istrain False\n"
     ]
    }
   ],
   "source": [
    "# Now extract .pt file from video using wholepose_features_extraction.py\n",
    "# NOTE: The directories must be changed in wholepose_features_extraction.py for now, might need to change that\n",
    "path_to_wholepose_features = \"../FeatureExtraction\"\n",
    "os.chdir(path_to_wholepose_features)\n",
    "path_to_save_pt = \"E:/ASL_Data/testing/video/pt/\" + file_name + \".pt\"\n",
    "print(\"./wholepose_features_extraction.py --video_path \" + path_to_video + \" --feature_path \" + path_to_save_pt + \" --istrain False\")\n",
    "os.system(\"python wholepose_features_extraction.py --video_path \" + path_to_video + \" --feature_path \" + path_to_save_pt + \" --istrain False\")\n",
    "os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f37eb7a0b74f2e22d6fd383ec5ebb97eab96881d30ca476017b85fc7b23292a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
