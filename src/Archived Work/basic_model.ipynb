{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template Project to build off of\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048\n",
    "\n",
    "LABELS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "test_df = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dimension = min(y, x)\n",
    "    start_x = x//2 - (min_dimension//2)\n",
    "    start_y = y//2 - (min_dimension//2)\n",
    "    return frame[start_y:start_y+min_dimension,start_x:start_x+min_dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a video file (.mp4) extract every n-th frame and return them as a numpy array\n",
    "#This will allow us to extract frames from a video and use them to train our model\n",
    "#Every frame would be way too much data but we can test and hone in exactly how many \n",
    "#frames will be needed for a good model\n",
    "\n",
    "def load_video(video_file, max_frames, resize=(IMG_SIZE, IMG_SIZE), n=1):\n",
    "    #if the video file is an array , just return it\n",
    "    if isinstance(video_file, list):\n",
    "        frames = []\n",
    "        for i, current_frame in enumerate(video_file):\n",
    "            if i % n == 0:\n",
    "                #frame = crop_center(frame)\n",
    "                frame = cv2.resize(current_frame, resize)\n",
    "                frame = frame[:, :, [2,1,0]]\n",
    "                frames.append(frame)\n",
    "\n",
    "            if len(current_frame) == max_frames:\n",
    "                break\n",
    "        return np.array(frames)\n",
    "    #if video_file is a jpg file then return an array of 10 images in a numpy array\n",
    "    if video_file.endswith(\".jpg\"):\n",
    "        return np.array([np.array(cv2.resize(imageio.imread(video_file), resize)) for i in range(3)])\n",
    "\n",
    "    video = cv2.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    \n",
    "    try:\n",
    "        current_frame = 0\n",
    "        while(True):\n",
    "            ret,frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if current_frame % n == 0:\n",
    "               #frame = crop_center(frame)\n",
    "                frame = cv2.resize(frame, resize)\n",
    "                frame = frame[:, :, [2,1,0]]\n",
    "                frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "            current_frame += 1\n",
    "    finally:\n",
    "        video.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A feature extractor will allow us to extarct only the most important parts\n",
    "#of each frame and discard the rest. This will allow us to train our model\n",
    "#faster and more efficiently\n",
    "def create_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    pre_process_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = pre_process_input(inputs)\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "feature_extractor = create_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(LABELS)\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 0 of 10863.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bencl\\AppData\\Local\\Temp/ipykernel_12236/3488690343.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return np.array([np.array(cv2.resize(imageio.imread(video_file), resize)) for i in range(3)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 100 of 10863.\n",
      "Processing video 200 of 10863.\n",
      "Processing video 300 of 10863.\n",
      "Processing video 400 of 10863.\n",
      "Processing video 500 of 10863.\n",
      "Processing video 600 of 10863.\n",
      "Processing video 700 of 10863.\n",
      "Processing video 800 of 10863.\n",
      "Processing video 900 of 10863.\n",
      "Processing video 1000 of 10863.\n",
      "Processing video 1100 of 10863.\n",
      "Processing video 1200 of 10863.\n",
      "Processing video 1300 of 10863.\n",
      "Processing video 1400 of 10863.\n",
      "Processing video 1500 of 10863.\n",
      "Processing video 1600 of 10863.\n",
      "Processing video 1700 of 10863.\n",
      "Processing video 1800 of 10863.\n",
      "Processing video 1900 of 10863.\n",
      "Processing video 2000 of 10863.\n",
      "Processing video 2100 of 10863.\n",
      "Processing video 2200 of 10863.\n",
      "Processing video 2300 of 10863.\n",
      "Processing video 2400 of 10863.\n",
      "Processing video 2500 of 10863.\n",
      "Processing video 2600 of 10863.\n",
      "Processing video 2700 of 10863.\n",
      "Processing video 2800 of 10863.\n",
      "Processing video 2900 of 10863.\n",
      "Processing video 3000 of 10863.\n",
      "Processing video 3100 of 10863.\n",
      "Processing video 3200 of 10863.\n",
      "Processing video 3300 of 10863.\n",
      "Processing video 3400 of 10863.\n",
      "Processing video 3500 of 10863.\n",
      "Processing video 3600 of 10863.\n",
      "Processing video 3700 of 10863.\n",
      "Processing video 3800 of 10863.\n",
      "Processing video 3900 of 10863.\n",
      "Processing video 4000 of 10863.\n",
      "Processing video 4100 of 10863.\n",
      "Processing video 4200 of 10863.\n",
      "Processing video 4300 of 10863.\n",
      "Processing video 4400 of 10863.\n",
      "Processing video 4500 of 10863.\n",
      "Processing video 4600 of 10863.\n",
      "Processing video 4700 of 10863.\n",
      "Processing video 4800 of 10863.\n",
      "Processing video 4900 of 10863.\n",
      "Processing video 5000 of 10863.\n",
      "Processing video 5100 of 10863.\n",
      "Processing video 5200 of 10863.\n",
      "Processing video 5300 of 10863.\n",
      "Processing video 5400 of 10863.\n",
      "Processing video 5500 of 10863.\n",
      "Processing video 5600 of 10863.\n",
      "Processing video 5700 of 10863.\n",
      "Processing video 5800 of 10863.\n",
      "Processing video 5900 of 10863.\n",
      "Processing video 6000 of 10863.\n",
      "Processing video 6100 of 10863.\n",
      "Processing video 6200 of 10863.\n",
      "Processing video 6300 of 10863.\n",
      "Processing video 6400 of 10863.\n",
      "Processing video 6500 of 10863.\n",
      "Processing video 6600 of 10863.\n",
      "Processing video 6700 of 10863.\n",
      "Processing video 6800 of 10863.\n",
      "Processing video 6900 of 10863.\n",
      "Processing video 7000 of 10863.\n",
      "Processing video 7100 of 10863.\n",
      "Processing video 7200 of 10863.\n",
      "Processing video 7300 of 10863.\n",
      "Processing video 7400 of 10863.\n",
      "Processing video 7500 of 10863.\n",
      "Processing video 7600 of 10863.\n",
      "Processing video 7700 of 10863.\n",
      "Processing video 7800 of 10863.\n",
      "Processing video 7900 of 10863.\n",
      "Processing video 8000 of 10863.\n",
      "Processing video 8100 of 10863.\n",
      "Processing video 8200 of 10863.\n",
      "Processing video 8300 of 10863.\n",
      "Processing video 8400 of 10863.\n",
      "Processing video 8500 of 10863.\n",
      "Processing video 8600 of 10863.\n",
      "Processing video 8700 of 10863.\n",
      "Processing video 8800 of 10863.\n",
      "Processing video 8900 of 10863.\n",
      "Processing video 9000 of 10863.\n",
      "Processing video 9100 of 10863.\n",
      "Processing video 9200 of 10863.\n",
      "Processing video 9300 of 10863.\n",
      "Processing video 9400 of 10863.\n",
      "Processing video 9500 of 10863.\n",
      "Processing video 9600 of 10863.\n",
      "Processing video 9700 of 10863.\n",
      "Processing video 9800 of 10863.\n",
      "Processing video 9900 of 10863.\n",
      "Processing video 10000 of 10863.\n",
      "Processing video 10100 of 10863.\n",
      "Processing video 10200 of 10863.\n",
      "Processing video 10300 of 10863.\n",
      "Processing video 10400 of 10863.\n",
      "Processing video 10500 of 10863.\n",
      "Processing video 10600 of 10863.\n",
      "Processing video 10700 of 10863.\n",
      "Processing video 10800 of 10863.\n",
      "Processing video 0 of 175.\n",
      "Processing video 100 of 175.\n",
      "Frame features in train set: (10863, 20, 2048)\n",
      "Frame masks in train set: (10863, 20)\n"
     ]
    }
   ],
   "source": [
    "# NEXT STEP: Create function using the above helper functions to load all the \n",
    "# video data that we plan to use, splitting them into training and validation sets\n",
    "# along with their labels\n",
    "# Then we can make a simple model to train on the data on, hopefully capable of \n",
    "# predicting the correct label for a given video (Fist or Hand)\n",
    "\n",
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        #if the filename starts with an int then skip it\n",
    "        #if path[0].isdigit():\n",
    "            #continue\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processing video {idx} of {num_samples}.\")\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path),20)\n",
    "        #if the size of the frames is less than 2 then skip it\n",
    "        if frames.shape[0] < 2:\n",
    "            continue\n",
    "        if frames.ndim != 4:\n",
    "            print(\"Frames is not 4D\")\n",
    "            continue\n",
    "        \n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                ) \n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "#train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "#test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"C:/Users/bencl/Desktop/data/Train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"C:/Users/bencl/Desktop/data/Test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(32, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(16)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "272/272 [==============================] - 18s 46ms/step - loss: 3.4388 - accuracy: 0.0567 - val_loss: 3.1198 - val_accuracy: 0.1201\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12011, saving model to tmp\\video_classifier\n",
      "Epoch 2/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 3.0355 - accuracy: 0.1207 - val_loss: 2.7094 - val_accuracy: 0.2062\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.12011 to 0.20617, saving model to tmp\\video_classifier\n",
      "Epoch 3/300\n",
      "272/272 [==============================] - 12s 42ms/step - loss: 2.7299 - accuracy: 0.1759 - val_loss: 2.3993 - val_accuracy: 0.2356\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.20617 to 0.23562, saving model to tmp\\video_classifier\n",
      "Epoch 4/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 2.4937 - accuracy: 0.2099 - val_loss: 2.2056 - val_accuracy: 0.2922\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.23562 to 0.29222, saving model to tmp\\video_classifier\n",
      "Epoch 5/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 2.3350 - accuracy: 0.2343 - val_loss: 1.9962 - val_accuracy: 0.3221\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.29222 to 0.32214, saving model to tmp\\video_classifier\n",
      "Epoch 6/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 2.2188 - accuracy: 0.2532 - val_loss: 2.0251 - val_accuracy: 0.3336\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.32214 to 0.33364, saving model to tmp\\video_classifier\n",
      "Epoch 7/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 2.1409 - accuracy: 0.2755 - val_loss: 1.8529 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.33364 to 0.37782, saving model to tmp\\video_classifier\n",
      "Epoch 8/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 2.0550 - accuracy: 0.2945 - val_loss: 1.7884 - val_accuracy: 0.4229\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.37782 to 0.42292, saving model to tmp\\video_classifier\n",
      "Epoch 9/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.9641 - accuracy: 0.3157 - val_loss: 1.7683 - val_accuracy: 0.4275\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.42292 to 0.42752, saving model to tmp\\video_classifier\n",
      "Epoch 10/300\n",
      "272/272 [==============================] - 14s 53ms/step - loss: 1.9623 - accuracy: 0.3216 - val_loss: 1.6983 - val_accuracy: 0.4335\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.42752 to 0.43350, saving model to tmp\\video_classifier\n",
      "Epoch 11/300\n",
      "272/272 [==============================] - 15s 53ms/step - loss: 1.8823 - accuracy: 0.3467 - val_loss: 1.6428 - val_accuracy: 0.4607\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.43350 to 0.46065, saving model to tmp\\video_classifier\n",
      "Epoch 12/300\n",
      "272/272 [==============================] - 14s 50ms/step - loss: 1.8513 - accuracy: 0.3464 - val_loss: 1.6611 - val_accuracy: 0.4404\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.46065\n",
      "Epoch 13/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.8501 - accuracy: 0.3528 - val_loss: 1.5517 - val_accuracy: 0.5076\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.46065 to 0.50759, saving model to tmp\\video_classifier\n",
      "Epoch 14/300\n",
      "272/272 [==============================] - 13s 50ms/step - loss: 1.7661 - accuracy: 0.3634 - val_loss: 1.5409 - val_accuracy: 0.4993\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.50759\n",
      "Epoch 15/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.7812 - accuracy: 0.3662 - val_loss: 1.6101 - val_accuracy: 0.4988\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.50759\n",
      "Epoch 16/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.7235 - accuracy: 0.3843 - val_loss: 1.5643 - val_accuracy: 0.4910\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.50759\n",
      "Epoch 17/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.6922 - accuracy: 0.3924 - val_loss: 1.4718 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.50759 to 0.50897, saving model to tmp\\video_classifier\n",
      "Epoch 18/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.6698 - accuracy: 0.4007 - val_loss: 1.6041 - val_accuracy: 0.4455\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.50897\n",
      "Epoch 19/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.6566 - accuracy: 0.3957 - val_loss: 1.4582 - val_accuracy: 0.5219\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.50897 to 0.52186, saving model to tmp\\video_classifier\n",
      "Epoch 20/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.6157 - accuracy: 0.4130 - val_loss: 1.4011 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.52186 to 0.55453, saving model to tmp\\video_classifier\n",
      "Epoch 21/300\n",
      "272/272 [==============================] - 17s 61ms/step - loss: 1.5927 - accuracy: 0.4176 - val_loss: 1.5103 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.55453\n",
      "Epoch 22/300\n",
      "272/272 [==============================] - 17s 64ms/step - loss: 1.6333 - accuracy: 0.4127 - val_loss: 1.4103 - val_accuracy: 0.5393\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.55453\n",
      "Epoch 23/300\n",
      "272/272 [==============================] - 18s 66ms/step - loss: 1.5927 - accuracy: 0.4283 - val_loss: 1.5020 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.55453\n",
      "Epoch 24/300\n",
      "272/272 [==============================] - 19s 69ms/step - loss: 1.5577 - accuracy: 0.4291 - val_loss: 1.3760 - val_accuracy: 0.5697\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.55453 to 0.56972, saving model to tmp\\video_classifier\n",
      "Epoch 25/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 1.5318 - accuracy: 0.4349 - val_loss: 1.3500 - val_accuracy: 0.5716\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.56972 to 0.57156, saving model to tmp\\video_classifier\n",
      "Epoch 26/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.5259 - accuracy: 0.4343 - val_loss: 1.4879 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.57156\n",
      "Epoch 27/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 1.5226 - accuracy: 0.4366 - val_loss: 1.3343 - val_accuracy: 0.5660\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.57156\n",
      "Epoch 28/300\n",
      "272/272 [==============================] - 14s 51ms/step - loss: 1.5242 - accuracy: 0.4404 - val_loss: 1.4213 - val_accuracy: 0.5209\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57156\n",
      "Epoch 29/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.4891 - accuracy: 0.4438 - val_loss: 1.3489 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.57156\n",
      "Epoch 30/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.5044 - accuracy: 0.4443 - val_loss: 1.4531 - val_accuracy: 0.5412\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.57156\n",
      "Epoch 31/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 1.4769 - accuracy: 0.4544 - val_loss: 1.3103 - val_accuracy: 0.5739\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.57156 to 0.57386, saving model to tmp\\video_classifier\n",
      "Epoch 32/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.4404 - accuracy: 0.4587 - val_loss: 1.3174 - val_accuracy: 0.5780\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.57386 to 0.57800, saving model to tmp\\video_classifier\n",
      "Epoch 33/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.4748 - accuracy: 0.4555 - val_loss: 1.3252 - val_accuracy: 0.5831\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.57800 to 0.58306, saving model to tmp\\video_classifier\n",
      "Epoch 34/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.4189 - accuracy: 0.4657 - val_loss: 1.2652 - val_accuracy: 0.5766\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.58306\n",
      "Epoch 35/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.4191 - accuracy: 0.4690 - val_loss: 1.2937 - val_accuracy: 0.5831\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.58306\n",
      "Epoch 36/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.4003 - accuracy: 0.4692 - val_loss: 1.3171 - val_accuracy: 0.5895\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.58306 to 0.58951, saving model to tmp\\video_classifier\n",
      "Epoch 37/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.4389 - accuracy: 0.4549 - val_loss: 1.3722 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.58951\n",
      "Epoch 38/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.3856 - accuracy: 0.4712 - val_loss: 1.3003 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.58951 to 0.59181, saving model to tmp\\video_classifier\n",
      "Epoch 39/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3934 - accuracy: 0.4795 - val_loss: 1.3100 - val_accuracy: 0.5665\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59181\n",
      "Epoch 40/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.3827 - accuracy: 0.4750 - val_loss: 1.4725 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59181\n",
      "Epoch 41/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3855 - accuracy: 0.4787 - val_loss: 1.3062 - val_accuracy: 0.5803\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59181\n",
      "Epoch 42/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3814 - accuracy: 0.4797 - val_loss: 1.3215 - val_accuracy: 0.5886\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59181\n",
      "Epoch 43/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.3391 - accuracy: 0.4879 - val_loss: 1.3038 - val_accuracy: 0.5656\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59181\n",
      "Epoch 44/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.3667 - accuracy: 0.4794 - val_loss: 1.2820 - val_accuracy: 0.5969\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.59181 to 0.59687, saving model to tmp\\video_classifier\n",
      "Epoch 45/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.3398 - accuracy: 0.4917 - val_loss: 1.4071 - val_accuracy: 0.5651\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59687\n",
      "Epoch 46/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3869 - accuracy: 0.4779 - val_loss: 1.3552 - val_accuracy: 0.5817\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59687\n",
      "Epoch 47/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 1.3233 - accuracy: 0.4916 - val_loss: 1.2680 - val_accuracy: 0.6102\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.59687 to 0.61022, saving model to tmp\\video_classifier\n",
      "Epoch 48/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3483 - accuracy: 0.4842 - val_loss: 1.2907 - val_accuracy: 0.6144\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.61022 to 0.61436, saving model to tmp\\video_classifier\n",
      "Epoch 49/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.3315 - accuracy: 0.4976 - val_loss: 1.2644 - val_accuracy: 0.5996\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.61436\n",
      "Epoch 50/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.3082 - accuracy: 0.5061 - val_loss: 1.4551 - val_accuracy: 0.5614\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.61436\n",
      "Epoch 51/300\n",
      "272/272 [==============================] - 14s 51ms/step - loss: 1.2840 - accuracy: 0.5045 - val_loss: 1.2966 - val_accuracy: 0.5932\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.61436\n",
      "Epoch 52/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.3019 - accuracy: 0.5047 - val_loss: 1.3095 - val_accuracy: 0.5996\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.61436\n",
      "Epoch 53/300\n",
      "272/272 [==============================] - 14s 52ms/step - loss: 1.2892 - accuracy: 0.5052 - val_loss: 1.2763 - val_accuracy: 0.6001\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.61436\n",
      "Epoch 54/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3306 - accuracy: 0.4987 - val_loss: 1.2722 - val_accuracy: 0.6203\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.61436 to 0.62034, saving model to tmp\\video_classifier\n",
      "Epoch 55/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.2640 - accuracy: 0.5120 - val_loss: 1.2240 - val_accuracy: 0.6323\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.62034 to 0.63231, saving model to tmp\\video_classifier\n",
      "Epoch 56/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.2499 - accuracy: 0.5222 - val_loss: 1.2421 - val_accuracy: 0.6180\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.63231\n",
      "Epoch 57/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.2905 - accuracy: 0.5086 - val_loss: 1.3519 - val_accuracy: 0.6056\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.63231\n",
      "Epoch 58/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2629 - accuracy: 0.5169 - val_loss: 1.2900 - val_accuracy: 0.6121\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.63231\n",
      "Epoch 59/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2633 - accuracy: 0.5176 - val_loss: 1.2159 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.63231 to 0.64749, saving model to tmp\\video_classifier\n",
      "Epoch 60/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.2668 - accuracy: 0.5208 - val_loss: 1.4374 - val_accuracy: 0.5904\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.64749\n",
      "Epoch 61/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2606 - accuracy: 0.5184 - val_loss: 1.2257 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.64749\n",
      "Epoch 62/300\n",
      "272/272 [==============================] - 12s 42ms/step - loss: 1.2731 - accuracy: 0.5169 - val_loss: 1.2102 - val_accuracy: 0.6420\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.64749\n",
      "Epoch 63/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2543 - accuracy: 0.5211 - val_loss: 1.2560 - val_accuracy: 0.6323\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.64749\n",
      "Epoch 64/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.2385 - accuracy: 0.5273 - val_loss: 1.2115 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.64749\n",
      "Epoch 65/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.2256 - accuracy: 0.5351 - val_loss: 1.2586 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.64749\n",
      "Epoch 66/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2386 - accuracy: 0.5325 - val_loss: 1.3174 - val_accuracy: 0.6231\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.64749\n",
      "Epoch 67/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2326 - accuracy: 0.5318 - val_loss: 1.2947 - val_accuracy: 0.6268\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.64749\n",
      "Epoch 68/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.2161 - accuracy: 0.5386 - val_loss: 1.3065 - val_accuracy: 0.6088\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.64749\n",
      "Epoch 69/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.1924 - accuracy: 0.5513 - val_loss: 1.1994 - val_accuracy: 0.6424\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.64749\n",
      "Epoch 70/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.1949 - accuracy: 0.5456 - val_loss: 1.2173 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.64749 to 0.65439, saving model to tmp\\video_classifier\n",
      "Epoch 71/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.4196 - accuracy: 0.4854 - val_loss: 1.2693 - val_accuracy: 0.6167\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.65439\n",
      "Epoch 72/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.3262 - accuracy: 0.5043 - val_loss: 1.3607 - val_accuracy: 0.5890\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.65439\n",
      "Epoch 73/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.3166 - accuracy: 0.5055 - val_loss: 1.2338 - val_accuracy: 0.6125\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.65439\n",
      "Epoch 74/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2555 - accuracy: 0.5245 - val_loss: 1.2694 - val_accuracy: 0.6277\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.65439\n",
      "Epoch 75/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.2528 - accuracy: 0.5244 - val_loss: 1.2946 - val_accuracy: 0.6162\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.65439\n",
      "Epoch 76/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2434 - accuracy: 0.5328 - val_loss: 1.2304 - val_accuracy: 0.6305\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.65439\n",
      "Epoch 77/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2478 - accuracy: 0.5258 - val_loss: 1.2563 - val_accuracy: 0.6295\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.65439\n",
      "Epoch 78/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.2247 - accuracy: 0.5295 - val_loss: 1.2148 - val_accuracy: 0.6323\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.65439\n",
      "Epoch 79/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2580 - accuracy: 0.5253 - val_loss: 1.3693 - val_accuracy: 0.6208\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.65439\n",
      "Epoch 80/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.2626 - accuracy: 0.5278 - val_loss: 1.7560 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.65439\n",
      "Epoch 81/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2389 - accuracy: 0.5303 - val_loss: 1.2794 - val_accuracy: 0.6309\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.65439\n",
      "Epoch 82/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.2031 - accuracy: 0.5403 - val_loss: 1.2411 - val_accuracy: 0.6107\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.65439\n",
      "Epoch 83/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.2366 - accuracy: 0.5308 - val_loss: 1.3382 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.65439\n",
      "Epoch 84/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1729 - accuracy: 0.5530 - val_loss: 1.2452 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.65439\n",
      "Epoch 85/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.2097 - accuracy: 0.5448 - val_loss: 1.2271 - val_accuracy: 0.6282\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.65439\n",
      "Epoch 86/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1870 - accuracy: 0.5471 - val_loss: 1.2803 - val_accuracy: 0.6240\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.65439\n",
      "Epoch 87/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1874 - accuracy: 0.5411 - val_loss: 1.2154 - val_accuracy: 0.6392\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.65439\n",
      "Epoch 88/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1802 - accuracy: 0.5459 - val_loss: 1.2320 - val_accuracy: 0.6282\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.65439\n",
      "Epoch 89/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1876 - accuracy: 0.5513 - val_loss: 1.2963 - val_accuracy: 0.6153\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.65439\n",
      "Epoch 90/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.1622 - accuracy: 0.5558 - val_loss: 1.2866 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.65439\n",
      "Epoch 91/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1473 - accuracy: 0.5547 - val_loss: 1.2578 - val_accuracy: 0.6360\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.65439\n",
      "Epoch 92/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1737 - accuracy: 0.5517 - val_loss: 1.2617 - val_accuracy: 0.6217\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.65439\n",
      "Epoch 93/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1488 - accuracy: 0.5651 - val_loss: 1.2267 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.65439\n",
      "Epoch 94/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1374 - accuracy: 0.5600 - val_loss: 1.2207 - val_accuracy: 0.6461\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.65439\n",
      "Epoch 95/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1513 - accuracy: 0.5564 - val_loss: 1.3199 - val_accuracy: 0.6148\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.65439\n",
      "Epoch 96/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.1493 - accuracy: 0.5628 - val_loss: 1.2820 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.65439\n",
      "Epoch 97/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1856 - accuracy: 0.5518 - val_loss: 1.1846 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.65439\n",
      "Epoch 98/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1312 - accuracy: 0.5644 - val_loss: 1.2384 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.65439\n",
      "Epoch 99/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1464 - accuracy: 0.5591 - val_loss: 1.1889 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.65439\n",
      "Epoch 100/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1687 - accuracy: 0.5590 - val_loss: 1.2388 - val_accuracy: 0.6461\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.65439\n",
      "Epoch 101/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1305 - accuracy: 0.5617 - val_loss: 1.2970 - val_accuracy: 0.6185\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.65439\n",
      "Epoch 102/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.1385 - accuracy: 0.5631 - val_loss: 1.4182 - val_accuracy: 0.6245\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.65439\n",
      "Epoch 103/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.1275 - accuracy: 0.5743 - val_loss: 1.5515 - val_accuracy: 0.5278\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.65439\n",
      "Epoch 104/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.1216 - accuracy: 0.5688 - val_loss: 1.3757 - val_accuracy: 0.6093\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.65439\n",
      "Epoch 105/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1282 - accuracy: 0.5631 - val_loss: 1.2533 - val_accuracy: 0.6438\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.65439\n",
      "Epoch 106/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1331 - accuracy: 0.5702 - val_loss: 1.2594 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00106: val_accuracy improved from 0.65439 to 0.65670, saving model to tmp\\video_classifier\n",
      "Epoch 107/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.0892 - accuracy: 0.5796 - val_loss: 1.3324 - val_accuracy: 0.6098\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.65670\n",
      "Epoch 108/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 1.1232 - accuracy: 0.5733 - val_loss: 1.3281 - val_accuracy: 0.6424\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.65670\n",
      "Epoch 109/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 1.1258 - accuracy: 0.5693 - val_loss: 1.3858 - val_accuracy: 0.6360\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.65670\n",
      "Epoch 110/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1276 - accuracy: 0.5686 - val_loss: 1.2669 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00110: val_accuracy improved from 0.65670 to 0.65992, saving model to tmp\\video_classifier\n",
      "Epoch 111/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.0638 - accuracy: 0.5841 - val_loss: 1.4029 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.65992\n",
      "Epoch 112/300\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 1.1035 - accuracy: 0.5684 - val_loss: 1.2840 - val_accuracy: 0.6420\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.65992\n",
      "Epoch 113/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1107 - accuracy: 0.5725 - val_loss: 1.2997 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.65992\n",
      "Epoch 114/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.1263 - accuracy: 0.5687 - val_loss: 1.2159 - val_accuracy: 0.6374\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.65992\n",
      "Epoch 115/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0960 - accuracy: 0.5803 - val_loss: 1.3976 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.65992\n",
      "Epoch 116/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0838 - accuracy: 0.5779 - val_loss: 1.3016 - val_accuracy: 0.6503\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.65992\n",
      "Epoch 117/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.2605 - accuracy: 0.5499 - val_loss: 1.3329 - val_accuracy: 0.5969\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.65992\n",
      "Epoch 118/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.1360 - accuracy: 0.5681 - val_loss: 1.4315 - val_accuracy: 0.6259\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.65992\n",
      "Epoch 119/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.0731 - accuracy: 0.5816 - val_loss: 1.3094 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00119: val_accuracy improved from 0.65992 to 0.66176, saving model to tmp\\video_classifier\n",
      "Epoch 120/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.0554 - accuracy: 0.5854 - val_loss: 1.3579 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.66176 to 0.66314, saving model to tmp\\video_classifier\n",
      "Epoch 121/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0667 - accuracy: 0.5824 - val_loss: 1.5295 - val_accuracy: 0.6019\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.66314\n",
      "Epoch 122/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.0987 - accuracy: 0.5776 - val_loss: 1.3369 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.66314\n",
      "Epoch 123/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.0445 - accuracy: 0.5908 - val_loss: 1.2539 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.66314\n",
      "Epoch 124/300\n",
      "272/272 [==============================] - 14s 52ms/step - loss: 1.0502 - accuracy: 0.5909 - val_loss: 1.2945 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.66314\n",
      "Epoch 125/300\n",
      "272/272 [==============================] - 14s 53ms/step - loss: 1.0585 - accuracy: 0.5830 - val_loss: 1.3260 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.66314\n",
      "Epoch 126/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0963 - accuracy: 0.5830 - val_loss: 1.4717 - val_accuracy: 0.5950\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.66314\n",
      "Epoch 127/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0757 - accuracy: 0.5860 - val_loss: 1.2850 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.66314\n",
      "Epoch 128/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0687 - accuracy: 0.5886 - val_loss: 1.4382 - val_accuracy: 0.6484\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.66314\n",
      "Epoch 129/300\n",
      "272/272 [==============================] - 14s 52ms/step - loss: 1.1256 - accuracy: 0.5734 - val_loss: 1.3321 - val_accuracy: 0.6590\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.66314\n",
      "Epoch 130/300\n",
      "272/272 [==============================] - 16s 57ms/step - loss: 1.0260 - accuracy: 0.6026 - val_loss: 1.3414 - val_accuracy: 0.6360\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.66314\n",
      "Epoch 131/300\n",
      "272/272 [==============================] - 18s 65ms/step - loss: 1.0394 - accuracy: 0.5969 - val_loss: 1.4327 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.66314\n",
      "Epoch 132/300\n",
      "272/272 [==============================] - 15s 54ms/step - loss: 1.0326 - accuracy: 0.5986 - val_loss: 1.3496 - val_accuracy: 0.6507\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.66314\n",
      "Epoch 133/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0625 - accuracy: 0.5928 - val_loss: 1.3975 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00133: val_accuracy improved from 0.66314 to 0.66406, saving model to tmp\\video_classifier\n",
      "Epoch 134/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 1.0618 - accuracy: 0.5892 - val_loss: 1.3235 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.66406\n",
      "Epoch 135/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.0259 - accuracy: 0.5936 - val_loss: 1.2837 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00135: val_accuracy improved from 0.66406 to 0.66728, saving model to tmp\\video_classifier\n",
      "Epoch 136/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.1357 - accuracy: 0.5703 - val_loss: 1.3444 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.66728\n",
      "Epoch 137/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.1093 - accuracy: 0.5776 - val_loss: 1.3160 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.66728\n",
      "Epoch 138/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.0526 - accuracy: 0.5900 - val_loss: 1.3556 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.66728\n",
      "Epoch 139/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.0141 - accuracy: 0.6006 - val_loss: 1.3650 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.66728\n",
      "Epoch 140/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.0912 - accuracy: 0.5910 - val_loss: 2.1808 - val_accuracy: 0.5720\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.66728\n",
      "Epoch 141/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.1394 - accuracy: 0.5671 - val_loss: 1.2626 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.66728\n",
      "Epoch 142/300\n",
      "272/272 [==============================] - 15s 54ms/step - loss: 1.0048 - accuracy: 0.5962 - val_loss: 1.2747 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.66728\n",
      "Epoch 143/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0105 - accuracy: 0.5965 - val_loss: 1.3128 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.66728\n",
      "Epoch 144/300\n",
      "272/272 [==============================] - 14s 53ms/step - loss: 1.0479 - accuracy: 0.5977 - val_loss: 1.5294 - val_accuracy: 0.6401\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.66728\n",
      "Epoch 145/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.0962 - accuracy: 0.5837 - val_loss: 1.4714 - val_accuracy: 0.6507\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.66728\n",
      "Epoch 146/300\n",
      "272/272 [==============================] - 16s 60ms/step - loss: 1.0446 - accuracy: 0.5978 - val_loss: 1.3279 - val_accuracy: 0.6457\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.66728\n",
      "Epoch 147/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0129 - accuracy: 0.5983 - val_loss: 1.3933 - val_accuracy: 0.6512\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.66728\n",
      "Epoch 148/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.0291 - accuracy: 0.6014 - val_loss: 1.5065 - val_accuracy: 0.6406\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.66728\n",
      "Epoch 149/300\n",
      "272/272 [==============================] - 15s 54ms/step - loss: 1.0137 - accuracy: 0.5983 - val_loss: 1.5050 - val_accuracy: 0.6489\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.66728\n",
      "Epoch 150/300\n",
      "272/272 [==============================] - 17s 61ms/step - loss: 1.0148 - accuracy: 0.6029 - val_loss: 1.3587 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.66728\n",
      "Epoch 151/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.0149 - accuracy: 0.5999 - val_loss: 1.3873 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.66728\n",
      "Epoch 152/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 1.0411 - accuracy: 0.5965 - val_loss: 1.4555 - val_accuracy: 0.6434\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.66728\n",
      "Epoch 153/300\n",
      "272/272 [==============================] - 16s 60ms/step - loss: 1.0801 - accuracy: 0.5881 - val_loss: 1.4820 - val_accuracy: 0.6484\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.66728\n",
      "Epoch 154/300\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 1.0374 - accuracy: 0.5938 - val_loss: 1.3927 - val_accuracy: 0.6493\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.66728\n",
      "Epoch 155/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.0118 - accuracy: 0.6013 - val_loss: 1.6574 - val_accuracy: 0.6231\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.66728\n",
      "Epoch 156/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.0061 - accuracy: 0.6077 - val_loss: 1.4637 - val_accuracy: 0.6489\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.66728\n",
      "Epoch 157/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.0582 - accuracy: 0.5847 - val_loss: 1.4331 - val_accuracy: 0.6512\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.66728\n",
      "Epoch 158/300\n",
      "272/272 [==============================] - 17s 61ms/step - loss: 1.0009 - accuracy: 0.6101 - val_loss: 1.5777 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.66728\n",
      "Epoch 159/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 1.0034 - accuracy: 0.6012 - val_loss: 1.5105 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.66728\n",
      "Epoch 160/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9821 - accuracy: 0.6119 - val_loss: 1.3882 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.66728\n",
      "Epoch 161/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0570 - accuracy: 0.5938 - val_loss: 1.3902 - val_accuracy: 0.6434\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.66728\n",
      "Epoch 162/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0024 - accuracy: 0.6121 - val_loss: 1.5821 - val_accuracy: 0.6420\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.66728\n",
      "Epoch 163/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0637 - accuracy: 0.5940 - val_loss: 1.4829 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.66728\n",
      "Epoch 164/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0575 - accuracy: 0.5885 - val_loss: 1.7457 - val_accuracy: 0.6406\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.66728\n",
      "Epoch 165/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0009 - accuracy: 0.6078 - val_loss: 1.4061 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.66728\n",
      "Epoch 166/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9816 - accuracy: 0.6130 - val_loss: 1.5472 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.66728\n",
      "Epoch 167/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.0307 - accuracy: 0.5994 - val_loss: 1.8132 - val_accuracy: 0.5665\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.66728\n",
      "Epoch 168/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9979 - accuracy: 0.6093 - val_loss: 1.5132 - val_accuracy: 0.6604\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.66728\n",
      "Epoch 169/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9824 - accuracy: 0.6171 - val_loss: 1.4555 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.66728\n",
      "Epoch 170/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.9778 - accuracy: 0.6086 - val_loss: 1.4926 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.66728\n",
      "Epoch 171/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.0140 - accuracy: 0.6068 - val_loss: 1.4306 - val_accuracy: 0.6438\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.66728\n",
      "Epoch 172/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.0165 - accuracy: 0.6010 - val_loss: 1.4392 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.66728\n",
      "Epoch 173/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9648 - accuracy: 0.6135 - val_loss: 1.4537 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.66728\n",
      "Epoch 174/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.0096 - accuracy: 0.6113 - val_loss: 1.4772 - val_accuracy: 0.6443\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.66728\n",
      "Epoch 175/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0874 - accuracy: 0.5899 - val_loss: 1.4540 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.66728\n",
      "Epoch 176/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.9709 - accuracy: 0.6120 - val_loss: 1.4543 - val_accuracy: 0.6576\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.66728\n",
      "Epoch 177/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9487 - accuracy: 0.6244 - val_loss: 1.4659 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.66728\n",
      "Epoch 178/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.0131 - accuracy: 0.6063 - val_loss: 1.4909 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.66728\n",
      "Epoch 179/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.0007 - accuracy: 0.6094 - val_loss: 1.4774 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.66728\n",
      "Epoch 180/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9775 - accuracy: 0.6154 - val_loss: 1.6670 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.66728\n",
      "Epoch 181/300\n",
      "272/272 [==============================] - 14s 51ms/step - loss: 0.9418 - accuracy: 0.6183 - val_loss: 1.4827 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.66728\n",
      "Epoch 182/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.0721 - accuracy: 0.5890 - val_loss: 1.7759 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.66728\n",
      "Epoch 183/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 1.0485 - accuracy: 0.5990 - val_loss: 1.4114 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.66728\n",
      "Epoch 184/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0043 - accuracy: 0.6037 - val_loss: 1.6748 - val_accuracy: 0.6378\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.66728\n",
      "Epoch 185/300\n",
      "272/272 [==============================] - 17s 63ms/step - loss: 1.0051 - accuracy: 0.5971 - val_loss: 1.4274 - val_accuracy: 0.6461\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.66728\n",
      "Epoch 186/300\n",
      "272/272 [==============================] - 18s 67ms/step - loss: 1.0427 - accuracy: 0.5906 - val_loss: 1.4946 - val_accuracy: 0.6116\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.66728\n",
      "Epoch 187/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9919 - accuracy: 0.6085 - val_loss: 1.5102 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.66728\n",
      "Epoch 188/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9753 - accuracy: 0.6124 - val_loss: 1.4198 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.66728\n",
      "Epoch 189/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.9863 - accuracy: 0.6139 - val_loss: 1.8917 - val_accuracy: 0.6157\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.66728\n",
      "Epoch 190/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 1.0125 - accuracy: 0.6029 - val_loss: 1.4898 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.66728\n",
      "Epoch 191/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9550 - accuracy: 0.6230 - val_loss: 1.3845 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.66728\n",
      "Epoch 192/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.0453 - accuracy: 0.6043 - val_loss: 1.5651 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.66728\n",
      "Epoch 193/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9483 - accuracy: 0.6207 - val_loss: 1.5827 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.66728\n",
      "Epoch 194/300\n",
      "272/272 [==============================] - 14s 53ms/step - loss: 0.9567 - accuracy: 0.6252 - val_loss: 1.7390 - val_accuracy: 0.5960\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.66728\n",
      "Epoch 195/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9744 - accuracy: 0.6100 - val_loss: 1.6712 - val_accuracy: 0.6443\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.66728\n",
      "Epoch 196/300\n",
      "272/272 [==============================] - 15s 57ms/step - loss: 0.9665 - accuracy: 0.6159 - val_loss: 1.6869 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.66728\n",
      "Epoch 197/300\n",
      "272/272 [==============================] - 18s 68ms/step - loss: 0.9421 - accuracy: 0.6236 - val_loss: 1.4607 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.66728\n",
      "Epoch 198/300\n",
      "272/272 [==============================] - 21s 77ms/step - loss: 0.9912 - accuracy: 0.6170 - val_loss: 1.7529 - val_accuracy: 0.5670\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.66728\n",
      "Epoch 199/300\n",
      "272/272 [==============================] - 15s 54ms/step - loss: 1.0210 - accuracy: 0.6070 - val_loss: 1.4935 - val_accuracy: 0.6498\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.66728\n",
      "Epoch 200/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9888 - accuracy: 0.6174 - val_loss: 1.8846 - val_accuracy: 0.5932\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.66728\n",
      "Epoch 201/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9963 - accuracy: 0.6157 - val_loss: 1.7034 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.66728\n",
      "Epoch 202/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9513 - accuracy: 0.6183 - val_loss: 1.9167 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.66728\n",
      "Epoch 203/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9482 - accuracy: 0.6238 - val_loss: 1.6403 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.66728\n",
      "Epoch 204/300\n",
      "272/272 [==============================] - 14s 50ms/step - loss: 0.9620 - accuracy: 0.6196 - val_loss: 1.5114 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.66728\n",
      "Epoch 205/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0193 - accuracy: 0.6075 - val_loss: 1.8161 - val_accuracy: 0.6052\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.66728\n",
      "Epoch 206/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9407 - accuracy: 0.6328 - val_loss: 1.6089 - val_accuracy: 0.6185\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.66728\n",
      "Epoch 207/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9493 - accuracy: 0.6212 - val_loss: 1.5703 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00207: val_accuracy improved from 0.66728 to 0.67096, saving model to tmp\\video_classifier\n",
      "Epoch 208/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9356 - accuracy: 0.6273 - val_loss: 1.4483 - val_accuracy: 0.6613\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.67096\n",
      "Epoch 209/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.0144 - accuracy: 0.6043 - val_loss: 1.6242 - val_accuracy: 0.6503\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.67096\n",
      "Epoch 210/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9677 - accuracy: 0.6214 - val_loss: 1.5593 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.67096\n",
      "Epoch 211/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9534 - accuracy: 0.6227 - val_loss: 1.4358 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.67096\n",
      "Epoch 212/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9289 - accuracy: 0.6274 - val_loss: 1.5665 - val_accuracy: 0.6443\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.67096\n",
      "Epoch 213/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9327 - accuracy: 0.6238 - val_loss: 1.7098 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.67096\n",
      "Epoch 214/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0056 - accuracy: 0.6148 - val_loss: 1.5732 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.67096\n",
      "Epoch 215/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9210 - accuracy: 0.6358 - val_loss: 1.6482 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.67096\n",
      "Epoch 216/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9275 - accuracy: 0.6280 - val_loss: 1.6954 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.67096\n",
      "Epoch 217/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.9555 - accuracy: 0.6244 - val_loss: 1.4453 - val_accuracy: 0.6604\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.67096\n",
      "Epoch 218/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9277 - accuracy: 0.6280 - val_loss: 1.5849 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.67096\n",
      "Epoch 219/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9291 - accuracy: 0.6339 - val_loss: 1.5831 - val_accuracy: 0.6466\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.67096\n",
      "Epoch 220/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.9958 - accuracy: 0.6203 - val_loss: 1.5890 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.67096\n",
      "Epoch 221/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.1037 - accuracy: 0.5972 - val_loss: 1.5926 - val_accuracy: 0.6489\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.67096\n",
      "Epoch 222/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9332 - accuracy: 0.6281 - val_loss: 1.7772 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.67096\n",
      "Epoch 223/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9425 - accuracy: 0.6323 - val_loss: 1.5197 - val_accuracy: 0.6507\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.67096\n",
      "Epoch 224/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9995 - accuracy: 0.6148 - val_loss: 1.7747 - val_accuracy: 0.6203\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.67096\n",
      "Epoch 225/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9503 - accuracy: 0.6199 - val_loss: 1.5758 - val_accuracy: 0.6622\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.67096\n",
      "Epoch 226/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9166 - accuracy: 0.6349 - val_loss: 1.6966 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.67096\n",
      "Epoch 227/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9036 - accuracy: 0.6396 - val_loss: 1.6274 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.67096\n",
      "Epoch 228/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9264 - accuracy: 0.6266 - val_loss: 1.8248 - val_accuracy: 0.6461\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.67096\n",
      "Epoch 229/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.9654 - accuracy: 0.6182 - val_loss: 1.6720 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.67096\n",
      "Epoch 230/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9990 - accuracy: 0.6257 - val_loss: 2.0526 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.67096\n",
      "Epoch 231/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9781 - accuracy: 0.6165 - val_loss: 1.5773 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.67096\n",
      "Epoch 232/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9054 - accuracy: 0.6336 - val_loss: 1.6558 - val_accuracy: 0.6604\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.67096\n",
      "Epoch 233/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9551 - accuracy: 0.6259 - val_loss: 1.6134 - val_accuracy: 0.6512\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.67096\n",
      "Epoch 234/300\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.0957 - accuracy: 0.6016 - val_loss: 1.5338 - val_accuracy: 0.6470\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.67096\n",
      "Epoch 235/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9117 - accuracy: 0.6338 - val_loss: 1.5041 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.67096\n",
      "Epoch 236/300\n",
      "272/272 [==============================] - 19s 70ms/step - loss: 0.9024 - accuracy: 0.6410 - val_loss: 1.6953 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.67096\n",
      "Epoch 237/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.8926 - accuracy: 0.6395 - val_loss: 1.5855 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.67096\n",
      "Epoch 238/300\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9168 - accuracy: 0.6329 - val_loss: 2.1421 - val_accuracy: 0.5960\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.67096\n",
      "Epoch 239/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.9366 - accuracy: 0.6259 - val_loss: 1.6071 - val_accuracy: 0.6604\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.67096\n",
      "Epoch 240/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9491 - accuracy: 0.6272 - val_loss: 1.5763 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.67096\n",
      "Epoch 241/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9094 - accuracy: 0.6369 - val_loss: 1.7009 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.67096\n",
      "Epoch 242/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9097 - accuracy: 0.6364 - val_loss: 1.7896 - val_accuracy: 0.6387\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.67096\n",
      "Epoch 243/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.9735 - accuracy: 0.6192 - val_loss: 1.8717 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.67096\n",
      "Epoch 244/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.9299 - accuracy: 0.6338 - val_loss: 1.8332 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.67096\n",
      "Epoch 245/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.9121 - accuracy: 0.6346 - val_loss: 1.7396 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.67096\n",
      "Epoch 246/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9259 - accuracy: 0.6342 - val_loss: 1.6149 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.67096\n",
      "Epoch 247/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.8929 - accuracy: 0.6433 - val_loss: 1.7116 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.67096\n",
      "Epoch 248/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.0777 - accuracy: 0.6039 - val_loss: 3.3860 - val_accuracy: 0.5527\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.67096\n",
      "Epoch 249/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.9421 - accuracy: 0.6303 - val_loss: 1.6907 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.67096\n",
      "Epoch 250/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9306 - accuracy: 0.6335 - val_loss: 1.6475 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.67096\n",
      "Epoch 251/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9504 - accuracy: 0.6334 - val_loss: 1.7314 - val_accuracy: 0.6576\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.67096\n",
      "Epoch 252/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.8995 - accuracy: 0.6388 - val_loss: 1.9123 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.67096\n",
      "Epoch 253/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9432 - accuracy: 0.6297 - val_loss: 1.9060 - val_accuracy: 0.6576\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.67096\n",
      "Epoch 254/300\n",
      "272/272 [==============================] - 14s 52ms/step - loss: 0.9064 - accuracy: 0.6386 - val_loss: 1.8910 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.67096\n",
      "Epoch 255/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.0565 - accuracy: 0.6185 - val_loss: 1.5052 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.67096\n",
      "Epoch 256/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9680 - accuracy: 0.6264 - val_loss: 1.7391 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.67096\n",
      "Epoch 257/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.8969 - accuracy: 0.6464 - val_loss: 2.1003 - val_accuracy: 0.6443\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.67096\n",
      "Epoch 258/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.8951 - accuracy: 0.6392 - val_loss: 1.7896 - val_accuracy: 0.6484\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.67096\n",
      "Epoch 259/300\n",
      "272/272 [==============================] - 15s 54ms/step - loss: 0.9098 - accuracy: 0.6403 - val_loss: 1.9181 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.67096\n",
      "Epoch 260/300\n",
      "272/272 [==============================] - 14s 52ms/step - loss: 0.9432 - accuracy: 0.6326 - val_loss: 1.7091 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.67096\n",
      "Epoch 261/300\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.8726 - accuracy: 0.6440 - val_loss: 1.8762 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.67096\n",
      "Epoch 262/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.8994 - accuracy: 0.6453 - val_loss: 1.6714 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.67096\n",
      "Epoch 263/300\n",
      "272/272 [==============================] - 14s 50ms/step - loss: 0.9381 - accuracy: 0.6296 - val_loss: 1.9326 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.67096\n",
      "Epoch 264/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.8794 - accuracy: 0.6473 - val_loss: 2.0974 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.67096\n",
      "Epoch 265/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.8766 - accuracy: 0.6479 - val_loss: 1.8635 - val_accuracy: 0.6622\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.67096\n",
      "Epoch 266/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 1.0489 - accuracy: 0.6198 - val_loss: 1.7889 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.67096\n",
      "Epoch 267/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.9578 - accuracy: 0.6315 - val_loss: 1.7755 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.67096\n",
      "Epoch 268/300\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.9010 - accuracy: 0.6357 - val_loss: 1.7766 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.67096\n",
      "Epoch 269/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8892 - accuracy: 0.6460 - val_loss: 1.8954 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.67096\n",
      "Epoch 270/300\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.8820 - accuracy: 0.6467 - val_loss: 1.7008 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.67096\n",
      "Epoch 271/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0551 - accuracy: 0.5985 - val_loss: 1.6629 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.67096\n",
      "Epoch 272/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8748 - accuracy: 0.6466 - val_loss: 1.5467 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.67096\n",
      "Epoch 273/300\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.9952 - accuracy: 0.6318 - val_loss: 1.7535 - val_accuracy: 0.6415\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.67096\n",
      "Epoch 274/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.8874 - accuracy: 0.6440 - val_loss: 1.8477 - val_accuracy: 0.6608\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.67096\n",
      "Epoch 275/300\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.8893 - accuracy: 0.6423 - val_loss: 1.7942 - val_accuracy: 0.6498\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.67096\n",
      "Epoch 276/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.9123 - accuracy: 0.6406 - val_loss: 1.9789 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.67096\n",
      "Epoch 277/300\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8752 - accuracy: 0.6499 - val_loss: 1.9310 - val_accuracy: 0.6576\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.67096\n",
      "Epoch 278/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8696 - accuracy: 0.6511 - val_loss: 1.8076 - val_accuracy: 0.6590\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.67096\n",
      "Epoch 279/300\n",
      "272/272 [==============================] - 16s 60ms/step - loss: 0.8682 - accuracy: 0.6468 - val_loss: 2.0179 - val_accuracy: 0.6590\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.67096\n",
      "Epoch 280/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 0.9041 - accuracy: 0.6412 - val_loss: 2.0042 - val_accuracy: 0.6470\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.67096\n",
      "Epoch 281/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 1.2511 - accuracy: 0.5681 - val_loss: 1.8788 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.67096\n",
      "Epoch 282/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 0.9230 - accuracy: 0.6414 - val_loss: 1.7759 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.67096\n",
      "Epoch 283/300\n",
      "272/272 [==============================] - 15s 53ms/step - loss: 0.8638 - accuracy: 0.6521 - val_loss: 1.6915 - val_accuracy: 0.6576\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.67096\n",
      "Epoch 284/300\n",
      "272/272 [==============================] - 15s 55ms/step - loss: 0.8686 - accuracy: 0.6433 - val_loss: 1.8342 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.67096\n",
      "Epoch 285/300\n",
      "272/272 [==============================] - 15s 56ms/step - loss: 1.0166 - accuracy: 0.6139 - val_loss: 1.9090 - val_accuracy: 0.6613\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.67096\n",
      "Epoch 286/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8749 - accuracy: 0.6449 - val_loss: 1.8574 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.67096\n",
      "Epoch 287/300\n",
      "272/272 [==============================] - 18s 65ms/step - loss: 0.8761 - accuracy: 0.6406 - val_loss: 1.8357 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.67096\n",
      "Epoch 288/300\n",
      "272/272 [==============================] - 17s 61ms/step - loss: 0.9235 - accuracy: 0.6376 - val_loss: 1.8389 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.67096\n",
      "Epoch 289/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9521 - accuracy: 0.6296 - val_loss: 2.0061 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.67096\n",
      "Epoch 290/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8924 - accuracy: 0.6468 - val_loss: 1.9005 - val_accuracy: 0.6489\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.67096\n",
      "Epoch 291/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9059 - accuracy: 0.6460 - val_loss: 1.8751 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.67096\n",
      "Epoch 292/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8545 - accuracy: 0.6577 - val_loss: 1.9608 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.67096\n",
      "Epoch 293/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8794 - accuracy: 0.6442 - val_loss: 1.6873 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.67096\n",
      "Epoch 294/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9840 - accuracy: 0.6321 - val_loss: 1.9631 - val_accuracy: 0.6355\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.67096\n",
      "Epoch 295/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9532 - accuracy: 0.6329 - val_loss: 1.7680 - val_accuracy: 0.6387\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.67096\n",
      "Epoch 296/300\n",
      "272/272 [==============================] - 17s 61ms/step - loss: 0.9384 - accuracy: 0.6330 - val_loss: 2.1755 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.67096\n",
      "Epoch 297/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.9058 - accuracy: 0.6449 - val_loss: 1.6544 - val_accuracy: 0.6493\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.67096\n",
      "Epoch 298/300\n",
      "272/272 [==============================] - 17s 62ms/step - loss: 0.8582 - accuracy: 0.6493 - val_loss: 1.9448 - val_accuracy: 0.6627\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.67096\n",
      "Epoch 299/300\n",
      "272/272 [==============================] - 19s 68ms/step - loss: 0.8697 - accuracy: 0.6486 - val_loss: 1.8750 - val_accuracy: 0.6705\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.67096\n",
      "Epoch 300/300\n",
      "272/272 [==============================] - 17s 63ms/step - loss: 0.9196 - accuracy: 0.6451 - val_loss: 2.0449 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.67096\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABaw0lEQVR4nO2dd3hcxfW/36Pee7Flyb33btOLKaYTIAQISQgESKEkAUIJX0L4pZBGEhISQicQei8GTK/GvfduS7Zk9V535/fH3KtdSStbklVs73mfR8/evXXuvav5zJxz5owYY1AURVGCl5C+LoCiKIrSt6gQKIqiBDkqBIqiKEGOCoGiKEqQo0KgKIoS5KgQKIqiBDkqBEpQISJPiMhvOrjvDhE5pafLpCh9jQqBoihKkKNCoCiHISIS1tdlUI4cVAiUQw7HJHOLiKwSkWoReVREMkXkHRGpFJEPRCTZb/9zRWStiJSJyCciMsZv2xQRWeYc9zwQ1epaZ4vICufYr0RkYgfLeJaILBeRChHZLSJ3t9p+rHO+Mmf7Fc76aBH5i4jsFJFyEfnCWXeiiOQGeA6nOMt3i8hLIvK0iFQAV4jITBFZ4Fxjr4j8U0Qi/I4fJyLvi0iJiBSIyB0i0k9EakQk1W+/qSJSKCLhHbl35chDhUA5VLkQOBUYCZwDvAPcAaRjf7c3AIjISOBZ4KfOtnnAmyIS4VSKrwFPASnAi855cY6dAjwGXAukAv8B3hCRyA6Urxr4LpAEnAX8SETOd847yCnvP5wyTQZWOMf9GZgGHO2U6ReAt4PP5DzgJeea/wM8wM+ANOAoYA7wY6cM8cAHwLtAFjAc+NAYkw98Alzsd97vAM8ZYxo7WA7lCEOFQDlU+YcxpsAYkwd8Diw0xiw3xtQBrwJTnP2+BbxtjHnfqcj+DERjK9rZQDjwN2NMozHmJWCx3zWuAf5jjFlojPEYY54E6p3j9osx5hNjzGpjjNcYsworRic4my8DPjDGPOtct9gYs0JEQoArgRuNMXnONb8yxtR38JksMMa85lyz1hiz1BjztTGmyRizAytkbhnOBvKNMX8xxtQZYyqNMQudbU8ClwOISChwKVYslSBFhUA5VCnwW64N8D3OWc4CdrobjDFeYDcwwNmWZ1pmVtzptzwIuMkxrZSJSBmQ4xy3X0Rkloh87JhUyoEfYlvmOOfYGuCwNKxpKtC2jrC7VRlGishbIpLvmIt+14EyALwOjBWRIdheV7kxZlEXy6QcAagQKIc7e7AVOgAiIthKMA/YCwxw1rkM9FveDfzWGJPk9xdjjHm2A9d9BngDyDHGJAIPAu51dgPDAhxTBNS1s60aiPG7j1CsWcmf1qmC/w1sAEYYYxKwpjP/MgwNVHCnV/UCtlfwHbQ3EPSoECiHOy8AZ4nIHMfZeRPWvPMVsABoAm4QkXARuQCY6Xfsw8APnda9iEis4wSO78B144ESY0ydiMzEmoNc/gecIiIXi0iYiKSKyGSnt/IYcJ+IZIlIqIgc5fgkNgFRzvXDgTuBA/kq4oEKoEpERgM/8tv2FtBfRH4qIpEiEi8is/y2/xe4AjgXFYKgR4VAOawxxmzEtmz/gW1xnwOcY4xpMMY0ABdgK7wSrD/hFb9jlwBXA/8ESoEtzr4d4cfAPSJSCdyFFST3vLuAM7GiVIJ1FE9yNt8MrMb6KkqAPwAhxphy55yPYHsz1UCLKKIA3IwVoEqsqD3vV4ZKrNnnHCAf2Ayc5Lf9S6yTepkxxt9cpgQhohPTKEpwIiIfAc8YYx7p67IofYsKgaIEISIyA3gf6+Oo7OvyKH2LmoYUJcgQkSexYwx+qiKgQA/3CERkLvB3IBR4xBhzb6vtf8Vnt4wBMowxST1WIEVRFKUNPSYETvjbJqzDKhfrHLvUGLOunf2vB6YYY67skQIpiqIoAenJxFUzgS3GmG0AIvIcdoh8QCHAjm781YFOmpaWZgYPHtxdZVQURQkKli5dWmSMaT02BehZIRhAy5GQucCsQDs6uVmGAB+1s/0abDoABg4cyJIlS7q3pIqiKEc4ItJumPCh4iy+BHjJGOMJtNEY85AxZroxZnp6ekBBUxRFUbpITwpBHnaov0u2sy4Ql2CTdimKoii9TE8KwWJghIgMcdIBX4LNzdICZ2h8MjYdgKIoitLL9JiPwBjTJCLXAe9hw0cfM8asFZF7gCXGGFcULsHmQu9y+FJjYyO5ubnU1dUdfMEPYaKiosjOziY8XOcPURSl+zjsRhZPnz7dtHYWb9++nfj4eFJTU2mZaPLIwRhDcXExlZWVDBkypK+LoyjKYYaILDXGTA+07VBxFh8UdXV1R7QIAIgIqampR3yvR1GU3ueIEALgiBYBl2C4R0VRep8jRggURekFdi+GXB3H0+vs+hqaOjqjaedRIegGysrK+Ne//tXp484880zKysq6v0BK19izAhpq+roUbfE02bIdCjx6CjwyB/bnW9z1NSx9omPnMwZqSrqlaL1KbSkUbemda+UugcdOhxX/67FLqBB0A+0JQVNT036PmzdvHklJST1UKqXDFKyDFc/AQyfAF/e13V5fBV5v75Zp33p4+ybwemD1C/DQiVAaYGBoeR68ci1UF3Xu/CXboLG26+XLX20/d3wBG9/xrTcG3vwpvPUzKHfm1WmohpLtgc/z4T3wxyFQXexbVx8gIaoxkL/G9x7qKuD16wI/k4aa/QtVd/DPmfDPaQfeb8Pb8Jcx9j1tmAdNDbZi9wYcOxuYJY/Zz70ru1bWDqBC0A3cdtttbN26lcmTJzNjxgyOO+44zj33XMaOHQvA+eefz7Rp0xg3bhwPPfRQ83GDBw+mqKiIHTt2MGbMGK6++mrGjRvHaaedRm3tQfyTBiMN1fDct+FvE1pWKgeiPBf+fRS85szyuP0z++n1wu+yYfGj8MBM+PtE2wrsDTyNsPA/sPgRW2HnrwYMFG1uuZ/Xa8u96jlY/VLgcxljW+f+z6SmBO6fAu/d4Vu35uW25w+EhNrPda/bcz9xFjx7iW/7lg+hcD0YLyx3WrCf/wUePK6laaN4K7x7u094d38Nix6GrR/D77Ptvfuz4AF48BjYtcBW9O/8ApY/BWta3XdlPvyuv31+Zbvts/Q0wstXw4pn4cFjYcG/4J1bYeXzLY8tz4OyXb7vq16EZQFm8ayvhOp9drm6GCr22kr++e/Yit6f1S9C5R54bC48dyn8fZLtUd07CP403B4L9j0/cXZbYaurgDXOpHr5a9qWpZvoyVxDfcKv31zLuj0V3XrOsVkJ/Oqcce1uv/fee1mzZg0rVqzgk08+4ayzzmLNmjXNYZ6PPfYYKSkp1NbWMmPGDC688EJSU1NbnGPz5s08++yzPPzww1x88cW8/PLLXH755d16H4ct6163/9hXvA3tOczXvwkb3rLLpduhbAe8/AO49DlIH+Xbr6kePv4dHHUdxKXDji/t+kmX2m0b3obGOijfDQ2V8NH/8wnAc5fDd1+H0B78t1n+NLz+E4hxfh/FW6Fwg10u2gieBkgeBJnjYNdXsP1TWzlvehdm/7Dt+XZ+CW/eaFuh5/3TrtvygXM+p+Iv2Q4vXQlZU+CaT/ZfvtBwaPLY5zTydN/6os1WWDbPh7hMSB1uK+rjb4a8pfZZFqyFAVPt/mtehq/9etHv/wqKN8OU79jvb98Eg46FjNHW1PT+XXb93pXw33PB6/S23d5DQw28eQM0OVF1u7+Gd2+FoSfB0BNtr2q1M5to/u0gITDkBJj0LXjpKiswFXsAA4OOgVPutmUAmHSJvW+wguQvoK//GHYvgqgEKN0Br1wNIaGQmANz7oJtzvMs3wXxWVBTBMfdZH+vRZugYA0k9Id374Adn1vRPsUv9+auBdBUC5kTYN86K/4h3d9+1x5BDzBz5swWsf73338/kyZNYvbs2ezevZvNm9u2vIYMGcLkyZMBmDZtGjt27Oil0nLo2WgX/se27l22fGArtMp82LMc3ri+bde6Mt+3XFcO826xrazP/gS5S32mgs3z4cu/wYY37fddX0FkApz3AEy8GDz18Phcnz02baT9TB0OO7+Arx8IXOaG6v078/LX2BbyGzfY1mlr6ith7ypragGocVrwxVugcKNd/uKvtlX576NtxVu81a4fc449ri5AA8g1J/gLqGvKSRthP5c9aT9j0toe/8b11nwDtrXbVAdRSbbV/9mfffv975tWVE+8A37wAcz4gRXTbR9bAQDYs8y3f22Z/TzrLxAWZUUArGiArahXv2B/my9+H6IS7frC9VYEsmdCZKJt9QMsfdy2vtc77zVhgP3c9jF8+gcYeDSERfuub7zW/FZbCmtfscJ7/M1w6j32eT96GtSX278dX9iWf9lu26vwZ8uHUFtiRQBg3Wuw9SP7G1v1gj3/ACd0/9Jn4fZcKxDfec2uK98NuxbCpneoMZHUL3+upRly1wIICYep34XGGtvI6QGOuB7B/lruvUVsbGzz8ieffMIHH3zAggULiImJ4cQTTww4FiAyMrJ5OTQ0tPdMQ1s/hqfOtz/MYScdaO/u4fO/QGUBnPnHwNvf+YX9NMZWYG53uXS7NYEs+y8cfSOkDfcdU13oW94831YoKcNs5bD6Rfj+u1CV76soXJv1rq8hZ5ZtxQ06GiLirNjsWW63x2XYz6nftdfe+hEcc6Nd11gLIc6/0COnQkMVXP6yr4J1qdhrn7F/GefeC7FOq7+mxNrJwXduCYHQCNi7Airy2t5j4QZr1pIQmP59WwHt+AJGn9ny2nlO5RsWBU+ea8+/5UNf+T1NPhNOTIrvuNylEJNsnzXAyLmQMtQuT7jImm42vwf9J1mxKd1uW/Mn3uo8t0yITrFi4ZZ7wzwrIqPOtJVnYo4VjCWP25Yx2Mo5ebC91pqX7Tkq98BlL8AzF0OVY5I5/bdWoMpzrUB9eT/0mwh1Zda8U+8nip4G2xsKDbfv703nGVflw9rXrCic+ScYONuuH3+RNXnFpFj/0df/sr+pyATbAJlxNRz1Y2te8zb6rnP23/D2n0J9eDzR/5oKH/4aJITqC55k+YZtHNN/ki8EPL6f7cmV50LuEupDYvh1/bf5Q/XDkLsYBjqJmncugKzJkO2IScEaSB1Gd6M9gm4gPj6eysrAM/6Vl5eTnJxMTEwMGzZs4Ouvv+7l0h2AlU4LxzU/9AYf3gOL/gPbPm27zd+B6S67ra2S7fafBGzLMG8ZPPMt2xL3rySLnWiOs++zLXmALe/Di1fYygVsxVVTYu/brQCiEuHGldZs5OKaHsKinUpvFfz3fNvjePA4W6ksfhT2rbWt+Feuto7bRQ9bs8C+DfDk2bbHcOlzcM799ny7/FJrff4X33JtmRWAqz+CzPG+1rvbmh14lO9ZlO+G+P6QM9u2GncH+G3tXmg/C9ZaM9LTF9hWLljh2vWVz97dVGd7Yzu/gkdOthWdy4J/2p4WQPYMSBxoy3nBw759cvyyzIdFwpTLffcpIbD1Q3j5KuuUry6E6GS7LdVP0DG2NT/+QvveP/+zNVkNPs5udnt+EXGQmG0r0oLVtlI/9mdw4yrbU/DvHU37vq08kwbanoE/Cx6wFbzbagdIHAA/WUTjd97AjD3HigBYcWmsthVz0mB7/36siprOcU+VMPNfW2hMHAyVe2HkXB5dUcvlb1ayfHeZb+eQUHuf+zbA2lf5OPxYPvJMttvcXlxjHWbPMlaFjuWtgiS8/SYCPTOWSIWgG0hNTeWYY45h/Pjx3HLLLS22zZ07l6amJsaMGcNtt93G7Nmze75AO76Ah07qWNyx223vTBRDZ9n+ua9l2lDtW//SlbDpvZb7uhU92G61p9EXfVKwxlfefRusk3LTu7ZSrC60LUmwTj+A9NFwueNo83cCRiZAyQ5fmXJm+rbFpsHMq2n+h3NNGOFRVghqS6y5YdFD1pyx/k3r8BxyvO3y71luHZLzbraRMx/eY4Xh2y/BqDMce3NkSyHwfwZ1ZVaQsqbYCrKhyq4fPsd+jjjVVqClO+xzScy2ZcuabE0MYN/lsv9a01G5YzpxzUgu0cn2Xax7HcJjrAmssQ4++b31U/gTlQRVhT4hiEq0LfJz/2H9L64ZZmCr3/axP/Mtn3iHbQFP/ra1je/b4PODuOY3l/j+MOGbkDXV/gYmXgLh0faduD2CiFjbo6jc43uPWVNsDzIs0tcjmHMXzP2979ypw+39uMJSvNn6EBy/z97yWspqGvjjB9sYcfen/LjqGrh+GVz9cfMpXtubwpJdZVREZNoV06+CaVfw50W1NHi8hIYIH9SNdrZdyYcbbJlfX25/l3WNzv9aUg5m0zvQWMOjFbOpi0qj1MTRmO/8xku3I54GHtkcz3UvrOfamL/SNOpseoIjzjTUVzzzzDMB10dGRvLOO+8E3Ob6AdLS0lizxhcRcPPNNx9cYXYusPbYqgL7z1Jb2rLb71Jf5esJ1HQy/LCj1JbaFjFYR+TuRXb55Dth5XPW8ebvdNz5lW+5fLet/N1pKta84lsuXG/vD6zttKrQmhNKd/hMKZEJEOqY4dzojMtesOaBZU859miB/pNbljl5MHz/HesIdB3FYdGQ5ud0ThhgTQ2lO2ylc9Z91rQ0/07bEkwcaCut0EjrfBx8jHOeSOsw3fw+zP6RFbrizbb1X7DG9lLc1r9rlhp9tjXbbXjLtv6T37Q9mvLdvpZszizbC2mqt728N2+Esef5ylvl50OJSoR+E6yDdf1bMPwU+yyb6mwvzK3wwfY0cmbZa7nrIxN89wO2cm2sbdWyx/7mLnzUtqiPvxmO+7ldXvE/qMj1mT+Gnmh7aqER9r0mZNnndPF/YeGDMPlSW8FHxPl6L5HxVgSN1wppZCIkD8YYQ7UnlPDqMiIBkgb5HL1gHa3ffR0Tl4HcNwYA78m/IgT4y/yN/OOjLZw4Kp2thVaAV+RVQOoMMIaikHQSPSX8v0Ueij9bwNPhCRwbCncUnMico2fx5YKlXH3cUCZlJ/K3Z05k4KhMMjKOYeXujwkPFd5atZeTRmdwxeOLefyKGZyUmI0YL5UmmmVmBHecMopN87MZnbuaRKBgXwGZwNhhg5k4cgy/eXs9D3++nR+d2P2mIRWCIxH3n6UyH179kW19Xre4rW1x70pf9IW/aaUrlO60rcyohJbrF/7Ht/zQib7lid+yFcuih32+AGgZwvjyD3wt2vAYpzITay/1D6Wrr7D3nDXZVlz1FdZ2Hx7ts+FX+PUSSrbbLv7m92xrtHWZAQYdZaM83Hj58CgbqYNYH8C1n1v78B+H2eNHnm4rnKOusxVqwgCY/0tfi9Ofqd+zkUEPnwxH/cSuG3OOFYLaMlsJgm0915baFq2n0bbgB86G5CFW6MvzYOz5dt+Bs635JneJz/zltp7j+1txcsmaAuGxULnZPtP+E22vrbHWlt09zn1ecen2ObitbNdx63LSL21DIlBE14SL7B/YHkF8f9+26BSq6ptYXD+Ck25YZnuIrhAAJOXA6b9ld0kNP3/iK54gklivY6qLiLVCANbsN+hYEGHZzlKSawzRniL6Q/OzrKxrJDo8lBARQrImU1RZzz0N15FvUsj+qIozJxTwyOfWb/TZpkK8TmxBYWU9Hq+hvLaRFxuOYrTspMqEAV52mQxq2cJzm4VnNtvR1mdP7M+4rASeGDyZ7+wezu2brdP/e0cN5pEvtvPGij0AXPv0UpbMziQBWMZoNv3uHGobPbz6Xg6TShZAXQXrtu0mEzhn1mgGjB9KWlwkp4/r1/YZdwNqGjoScf+Rlz1pI12Mx9q07xvri7IAX+UQEt652HuwrWm3le312tho/7C6ynxb0a9yQvYiW1W2iTmQkG0rnhq/a1fvs45N8ImAuz9Yx+igo20opUtduTW/xGVAZJxdF5XomAkibKvcvdfIeEgZ4rsHN5wxEGGRPnt6WLQ994SLYOY1Vhgi4+HE2+CUX/tanaf8ylbcSU55vU2+ZZfJl8K3X7St8I9+Y1vnGWOdeymz5wYbOnneP+11YlKsozck1PZYSndYIXIrwyEnQES8Ne24IbFub6+18zprqq1IXRNaVJJ95m7vp2KPb99hJ9rttaU+u3tr4Rw4C0afBUB9k4eKukbaxV8IYlL55oML+P7ji20L3DUx+e8DPPTZNpbsLGVfnTOGISScJgnn6c1+1Ve/CQC8vWovDYQTYxwTZFgUxVX1nPCnT/jz/E2MuPMdfv/OerYWVvGm92gWm9G8ujyPn/xvGbWNHk4dm9ksAieNSqfJayiqqufjDfv4Q9MlPDfyPuqbvPRLiOKBpvO5suFmvjVzEL+YO4orjh7MuKwERIS54/tRUt3AtiJbjqOHWzPYhnwrZFFhIfxrhR1zsC1uGqEhQlxkGFWJI4nyVMG9OYRtsZaErH628j9/ygCiI0Lbf7YHgQrBkYjbui/ZYT8zx1tHXUWejaBxcQUjc9z+ewStR2k2NdjW7H2jrSmnZJs9ftO7VhSq9sFfRsGzl9ptYdEtoziGnGAr6UTnH9/1AYA18bSuuABOuh0yxsGcX7U0eYDtjRgPxGbYyhBaCk9kvC++PDK+5biCAfsZHRruF27oVs4XPuL4EByO+zlM+TZtSMwJvOwy7GRrSvE0wPG3+K5VW9oyzDEQri8ErAMUbOU8/Qobix6dZMXdrdhdG3xYlDXVzP6RFYJGp7KMSrL35+7viuYFj8Bpv7E9vaZa6soc81LrHoEfP3t+BRPvnk+jx4ZArt1TzjML/fwzsekYp5e2qTKc9Xvt72LhtpJmUauP7cdLS3NtS7ymkZeW5nLR1GxMhI3GM5FxfLa5kDs/reF3jZcC8GrFKC7891c8v3gX9YQT5bH3tiS3ilteWkVJdQOPfrENj9fwn0+3sWWfNf3Mu+E4/nDhBBo8XsJDhauPG9pc1JNGW9PcrpIanvp6J/0Sojh2uA2xrW/ykEc6C7zjmDM6kx+fOJy7zx3XHBUU41TYxVXWTzckzTZQNhZUkpMSzZNXzuSL6mzqTTilA3zRerEDJzYvp1dYX4FEJbX7vLsLFYIjgSWP29a+O6rRreDLd9kKYZL9ZyEi3jdKEWyLNCTcVkitfQTG2Nb8wofsSM91r9v1Xz9oKxuXN38KuY7dv7oQ8lfa3gfY2H+Mz9EJ1pbuxlC7rVnXbOOWyd95OOpM+OlqGPcN+PFXtpIbMA1u3gzfcsIe3SihuPSWPQIXd11YtG25Jw+2/ooLH7Xml/ZweyatlzuCW0G3XnYRsSaV8RfC6HN8QtBQ5TMNtcfgY22oZNZU++dy1HUw4nQbnZTlRPyEx/ha2rHptkcTl2GFwCU6yT6bujL73fXDRMb7tgNfLV2KF/GJbQDmrbZi8eH6Ajxew8+fX8kvX1tNea3tJdz91nryvfbdrCwOITYilJTYCBZtL4Zhc2D4qbxTkMzNL67k7dV7WbqrhNpGDxdNyyYp0UYZ1RLFu2vyiY8M46mQ8/lmxlv8bHkGNQ0eRmTG00AYkcYK/+/m7+CjDfuYMjCJRo9t0KTGRrC1sIqYiFBG94vngqnZZCZEMnNICpNzkogICyE+Moxpg+z17nhlNSt2l/HLs8aQGGMjhUpr7P2Ehgizhrb1v0VHWLErrmogMiyE/on29+PxGvolRDFlYDJRA6cxtv4x0oeMbz4uZ+JJ/KThBgAGGMcHFsh02c2oj+BIYO2rtjItWG0rSddHULHHtvZmXGXNE+V58N7tNoGZiK104zJtBeHmqvF64Kv77Xle8Wv5rnjWVjLv3upbN+NqWPwwvPVza37x1MPGd52QRwGcnsSwk32jfpMH+UZGJjhC4PYIPI02Kid1uO/4xOzAFWlcho3CAdvrAHsfEa4QtOoRtF6XNcVXWbZH+EEIQUyqrVybagOXH2D8BfYPWvYCwg/QI0gdBj/8vO36+H7wbccU5zqaY9N8YZpulA60FIKoJCs+rr/IpVlUk+zhNXlUmyg27S4jOjyMsVn2eW7Ir6CkqoGjh6eREBVGRV0TT3y1g4raJjYWWFPI8l2lRISF8MRXOzgvIpn+IcWsKQtnQnYiqXGRLNxegkmdjFz+EqveXAfA01/v5BtTrIhlp8SQnJQMxbCvPpz31xUwZ0wGe8rqWLTDDoh88PKpDEqNZd29seB0AGcM68djl51KZFgoM3/3AZV1TRRXN7Amr5yh6bGEhAghCM9dcxRR4SFEhIUwKTuR8NAQshLte9i8r4qTRqVzzqQsPt3k6znPHprCBVOyiY9qO2NgrNMjKKqqJyYilKjwUJJjwimtaSQjwf6WLps1kCU7S5mYndR83PEjM8g95yo8HzxEvKcWExaNHKhh0A2oEBzuNNbaQVFgUwRnTvBFd3ibbMs4PNqaU2pL4dN7bRw32AoiZaitLBqq7Ln2LIcP7rYOSYDzH7RRNpveaxn6CXZQzb51tuUfn2XPs/QJKwizf2JH4YZF+2LfwVf5g90/NNKGYCYNtOGZ4AxGSrLljcts/95DQm3F7/YIYtP9Kn2/HkGzuaj9lmxAOlM5t0bEJ75uRbw/OiE6dY0eXlqay6UzBxIa0k5cebMQpDe36IlNb97cFBbt++ePTqLSE0abpxMZz+6SGhIljgQg01NAucRy4b9t6OuOe8+ipLqByx9ZSEl1A3+4cCIVdU1kJ0fz9bYSFm4vYXJOEqvzylmyo5T6JtvTyDf2eawqCmHm6CSyk2N4e9VeXliym8e/3NF8+UXbS8hOts89PS4SibTiVdoUQWlDIxdNy+H9dfks2lFCSmwEA1NiAFpUnDNG9CfJacXPu+E4Fm4v4eYXV7J4R2mzyAAMSfMJ4z8vm4oASTG+Ct41EyVE+arMY4alcfGMAGY/aLblF1U1EOP0DvolRlNa00hmvH2/35gygOEZcS2EIDRE+M5Rg2FBGlTkIr3QGwA1DXULXU1DDfC3v/2NmpqDSH28e6GteMGaaFrb+t1KAGyFdMxPfd/dijbWSS1QXeSLyS7dblMOTLrEjlatL7eDj5oRW6lf+Kg1L037njVZuGGKky+zFWnGGJ8vAFoui9jKacfndkyAa9KKy2huhRJ/gCiJyASfTTu+v68VG+lvGuqiEBxMjwCsyKYMbT8/kj+dMEO9ujyPO19bw8Jt+3HwuwIam94sRJ7oVKb/5gNeX5HHB1t9ol4lMby4oq2PqNwTxdn/+IJb3rI2/hwppNL4BHHR9hIueWgB5bWNDE2P45aXVgHw63PHcdWxQ5gwIJHHrpjB2P4JLNlZQkFFPQOSoikSa0op9MYyOTuJueP6ERoi3PHqGjbkV7Ihv5Kx/W0F+MXmIpJjwokIC2nu7fVLT+OdG4/j2BFpzb2SyTlJzfb5kHCfEKQn+SrSnJQYJmb7fhdzxwf+bWUmRJGRENViIijXN5AY7ROHxJi2PQEXt/Ivrq5vFgXXPJSZYMsnIi1EoOUJHHPTfvwx3YkKQTfQp0Kw8ys7anP4qbZHUL2v5fbWP6Sjb4DvvOpzpsZl+FqKNUW+XC9gB1qJ2NA88EWjgBPrHWETZt2xB0641cbLgw1NzBhjewxTv2OvFR5jK+fWlXGFv6PYFYJMn4DFHUAI3PsLj7XLEQF6BM3i0Is9AoAz/ggXPdqxff3Ob8KiKKpqfzDgV1utALgRKGU1Dfz7k61U1/uZdtx36icEpSRQVFXPB+v38f4WnxC8tqGGCk9b48A/viqgsq6RTRW2wgsTL43hvmd42yurKKtp5B+XTuHm03x+naHpcfzf2WN547pjSYmNYNqgZFbuLie/vI4BSdHUxA2mzoRTbOKZlJNEenwkJ41Kx+OG60BzmOS+ynoyHVOKa87qn57GGEco3M/JOUnNx4b4CXhGSsvf/6DUmOblOU4rvyO4PYYWQhC9PyGwlX9do7d52b2P5vvZH64ZT4Xg8ME/DfUtt9zCn/70J2bMmMHEiRP51a9sJsHq6mrOOussJk2axPjx43n++ee5//772bNnDyeddBInnXSAPD/epsAjhQs3WDPOsJOtc7j1BCatIw5Cw+y+/ZzohLhMX7KxqkIbn+62JrNnOOdwfoz+aZj9I2HCIhzBcIbv95tgzTZz7oLpV9ptcZm++HB/zvyzr5yuiMWm+/UI9mMaAp/dPyHLXidyPz6C1iGsB+JgewTJg1pGKO0Pv/OvLWzgmHs/oqCibU4qYwwLHCHYmF9JWU0DR9/7EX94dwNfbvFz+PubhpxnWeC1z+H9dflUeW2rtMZE8q/PdhEXG9fmWk8tK+b7xwxh+hhfAsURw0fx4OU20mpbYTVnTezP3PH9OXGUr1LNSW4pmsMy4qht9LB2TzkZCZF8nXIOpzf8gePHDSIrye575TFDGJgSw/eOGgTYcMu4SCtO6fFOC9/1a0T4yjouK5HrTx7ON6f7TI5hEb5nmZ7YUvwjw0K5ZEYOf7hwAmGhB67+5v/seN647pjm3kGCX+WfEMA34BIdHtpm2dcjOPSE4MjzEbxzm28QUHfRbwKccW+7m/3TUM+fP5+XXnqJRYsWYYzh3HPP5bPPPqOwsJCsrCzefvttwOYgSkxM5L777uPjjz8mLS1A5kcXr9fvnlr9iIo22yibwU6r3R1MFO6EB7b3Q8oca8cYxGXYVj3YfDmlO+Dk/7MjNqc4abBDwwFpOeK0dWw82O7sxEt8CbL8yZ4RuFU982qb/mHRQ76RwnEZHe8RRPoJAfgqCf9KP6KrPYKDFIIAbC+qZk9ZLZkJkWzIr+Tsibbc720qxx1fvXJvHfVNXl5bnse1Jwzj623F/PS5Ffzs1BFMG5RMUVU9IrChoJJ/frSFmgbH9u4vHI6YN0Sl8rO3Czim6STe2zYYsK3U6hB7P+XEsqe8jlkzBoDfv02DCeWG08bzoxOH88LiaHAyVEQOPaZFq9ptkUeFh3LupCw2FVS2qWAHObb76gYPmQlRTBiTyS+2V/GsX4LIo4en8dkvTqKyrpFhGXFMG5hMdnI0G/IryYhv2SNoFnusTf2m01qKbXik73cWFtn2N3fvhRPbrGuPkZktfzPhoTbSqbrB00IUWhPjF+/vLrvPLTu5A71LFYLDm/nz5zN//nymTLERKVVVVWzevJnjjjuOm266iVtvvZWzzz6b4447ruMn9U8P4B/Z4fVYR+nwU+xYgehka2+PTLC26b0r2v8huQOY4jKdATziy0rZfzKMOMW3r4itxN3wQvBlomzNBf8JvP7ChwOvB1vJuiNaI+LsP3x0sh2J6h/pEoioVkIQyFnsikJXhSA0oss54OubPBgDzyzcxcLtxTQ0eVmyo5Q5YzJ4e/VeThvbj6r6Jq59bi07nMsV1dvK5qWluVxxzGDeXLmH/Io6bn15NTfMsWMsjh2exuebi1i/p4ILpg7gjRV7yC/3E4KUoZjwWP69IZp5Wwt521wNfh268Og48ECFsZXTuIEZLYQgLCaRn5xsr3X0cF+vLGTQUc0VO9Bsywf4+yWTW9jVXfyFo19CFOdPGcC5k7IICeDojo8K57tHDQZgYEqMFYIEt0fgCIB/xFMAIiL9RDu0+yNuEqLDqW7wHMA0FNZm+awJ/clJiSHH7/m1f4IjSAhEZC7wdyAUeMQY06ZZLSIXA3djYw1XGmMuO6iL7qfl3hsYY7j99tu59tpr22xbtmwZ8+bN484772TOnDncddddHTtpo58PwX8GpLKddkBS2khbUQ0+1kbgzLrWl0bZ31nsz5DjbaROv4m2xR/f35fwLWVI2/3DIn09gpP/z6YP7i5cE0zVPl+EzeRvW7E5UAXcukcQ0DQUoJfQoXI5LbcDDfDaD2f8/XO8XsOOYvsOw0KEJq/hs81FNHoM24uqeXeNTZ1RayKIlgYIi+JXZ4/jFy+t4sy/f059k5fU2AiKqxuYvzafEIHTxmby+eYiGjxebjptFAu3lbQUgtg0tv5gA3/96+fcMGcE5TUNPLlgJ4nR4ZTXNpKVng75kJSSzjvfOo6QgrdblDvEr9U90K8iJ2MsMSEhpMdHUlrdwPAM336BRABgQFJ08327lXogEWiNW2FmtDEN7V/QI6Ps+/IihIS2X1l3lcTocPaW1+1XCKLCQxCxw3FcZ3FYaAhTB3YgggyOHGexiIQCDwBnAGOBS0VkbKt9RgC3A8cYY8YBP+2p8vQk/mmoTz/9dB577DGqquzIxby8PPbt28eePXuIiYnh8ssv55ZbbmHZsmVtjm0XT6NTiYkvQgh8eXncAVhjz7e2+9k/Dtwy9id1mB2olWxtsiQOsK1yCQk8EjYs2peJc8jx7QtMV3Bb3rUl1qkM1rx09PUHPrZ1jyCgs7hl1JAxhqe/3klZTatpBdsrV3j7ZqGGJi8er+Gd1Xt5f11Bi20rd5exrbCaHcU1RIbZf7UmxyFaUm2vvSG/gnV7bUx7vdgwx8H9Urh4eg4Pf3c624qqyS2t5bJZA539K8lOjmHOmEzmjM5g/s+OZ0BSNP0So9hbXkdeWS1XPL6IDfkVrM+3v8HTx2U22/BPHWtb94P6W2dyZkY/a95pfY+tRNMTkUhTbP9mYR6SFsvwjDii/Gzh7T7G0BAGOOaQDtnHHVxfQxvT0AF6BFFR9jfkkYiORWx1EtcklBDdfjtaRJp9AzFdSQtxBPUIZgJbjDHbAETkOeA8YJ3fPlcDDxhjSgGMMfvanOUwwD8N9RlnnMFll13GUUfZ2Pm4uDiefvpptmzZwi233EJISAjh4eH8+9//BuCaa65h7ty5ZGVl8fHHHwe+gKfRVmJeD3jK7LqiLfDVP+yym5LBP8HXgYSgNQkDgMU2JDQsou328Cg7mQy0ycN+0Lhx37WlnY/Oae4ROGGpSQMB8Y1ahjY+go0Fldz52hqe/nonD31nOjkp0W1as8YYHvwyjx9Bu/6B7UXVfPexhcRGhLF5XxVeY/jDBRObY8sf+HhL8771TTblQnR4KLVuGmJgU0Elm/dVMTIjHlMTBZ4qRg7wVdrfmDyAV5bncfq4fjyzcBfF1Q0MToslKymaR6+Y0XyefglRrNtbwS9eWsmXW4oJFWFM/wRCQ4ThGXEMS49j1pAULpyazZkT+jEl1QPL8Ql663tsZUYLvWUj/rnw/99545vTSHSEgSkx7CyuoV8nhGCEY59vNi01v8e2jm1/3B5BaET3+HVakxgdTlR4CJFh+6/gYyJCqWnwdC0/UC/3CHpSCAYAflnDyAVmtdpnJICIfIk1H91tjHm39YlE5BrgGoCBA9sZpdnHtE5DfeONN7b4PmzYME4//XRac/3113P99QFavnUVvgFhxmNj9cOjrSgYA69eawdzjb8ocIppt4LsaJ4St+J0ewitCYvy5abpJsep79x+eXb8B5x1BPcfxe0RDDoKbtrYMtqo2UdgP/c6JpQN+ZUc/6ePueX0UfzkpJYplNfkVfDFzmp+FAGER/PJxn18tbWYzzcXcenMHD7dWMiHG/aREBVGQXk96XGRDM+I49ZXVhEeJkwflMIH6wsY2z+BdU4+nR8cO4RTx2by8xdWkldWS0RYCKvzKthZXMNZE/oTnh8D1TAsy+cXueucsRw1LJVxWQkMSYu1QpDa1sbcLzGKt1fvZXtRNWP7J/Dhhn1sL6pmSFpsc4X1/LV+A/vcSX/c59fsD4m0yewiWlW2rQR6VL/O+VsGpcbw+WZ89v4OcPSwVN66/ljGD3DKGCBqKCCOXyCkh0bk9k+Mon/igRssrgDEhHehmnUT7/kNAuxJ+tpZHAaMAE4EsoHPRGSCMabMfydjzEPAQwDTp09vlQHtCKWqwNr/XVNJaDjgtdE8m9+HvCVw9l9teGYgmnsESR27nisEgfwD0CqCppv/wZp7BGWQGiDh3P4YfCyMPKNlfqLWIacxyS0+XVv6yMw4BOHfn2zl4uk5vLwst9mh9+GGAuqM7fk0hkRy3TPLqWv00OQ1PLVgJ1sLqzhtbCZ3nDmGuiYPMeFhZCREctnDX/Pbtzdw3mQrTHecOYbLH7UTxhw7Io1ZQ1MZ1S+ePeW1nDAyvdmcNDwjjrjYeKiGiEhfRZ8UE8E3p9sexpC0WJbsLGVwalvTiH9L+7ErZnDqfZ+yrciGdwYkLMpWNm5v0n2/ETH2N9ZZx/oBuGhaDskxES2cqAdCRHwiANZkGRLW/m/Uxf09dXeDxeGmU0e1SE7XHrHOvXbJNJQ+Cr77um8MTw/Tk0KQB/gbm7Oddf7kAguNMY3AdhHZhBWGxRzpNDVYe3xFrv1xJ7ZqCXub7HyyHseOHRrhSwa27Enbut1fwjS3FdxRW75rWknuAyFwW5v1FZ03DWWMgcuea7O6qKqeO19dQ6PHy+8vGE/GJc/CUDtWY295HSECb99wHDuKqjnj759z5v2fU1hZz56yWu45bzwfrt9HalwcNEJhrVBV38SdZ42hsKqe/3xqcxt9e/YgBqe1rJSvPWEY1z61lEe/2M45k7KYMSS52WmYnWwr+IumZZOTHM3E7KQWQtBsp2/nGQxJt9caktZWCDKdGPXBqTH0S4ziu0cP4oGPtzI6s50KXcRO6+jO1+BeOyzaZqPNmhz4uC4yOSepxaCvLpE8CG7P26/PBvATgm42YTokxoTvd1Sxi9sj6HLq6NbzWPQgPTmgbDEwQkSGiEgEcAnwRqt9XsP2BhCRNKypaFtXLmZap0o+lPF67XR9Fbl2lqj6Kt+2ku02rbKnEfD60ieHhmMkFDB2TEFizv4r5JxZdqSvW8EfCDcctPW0gS4HO7hqf/jfR3hbs0dXeG9tPu+uzefDDfv438LdMPpM3l1XyDH3fsRHGwpIi4skPDSEEZnx/O4bEyistE74yromiqvqWZ1XzqkTrZlsn2NF6ZcYxTS/qI9AFdvJozNIjY0gIjSEX5w+isiw0ObkZQOcwVNnTujPr88bz/l+uW6Gpcf57r2d9zp9UArR4aHNaRX8SYu1ld55k+05rzp2KLOHpjBnzH4G5IX5hcWG+YnQ5S/ZuQ8ORQ4kAuALGe2hHkFHcXsCXeoR9DI91iMwxjSJyHXAe1j7/2PGmLUicg+wxBjzhrPtNBFZB3iAW4wxnZwhBaKioiguLiY1NbXdELZDAm+T7QXUFFk7rKeh5bgAT2PLWH2wQgGYkDCKy6uJKt9mw0aHzWG/ZE+D78/reNn6jYfvv9tyAnJ/etQ05HfudlrDuaU1fLW1mIunB07yBbby/9289fz2/Aks3l5CenwkY/sn8Pzi3cRHhfHbeesxBvLKapnkl3Pm4hk5TMhO5M7X1rCzuJqvt9lslpOG9oelNq4frPnF7QGMyIgLGD4YHhrCb84fT32Ttzn8cVBqDPVNbZ2GoSHCRzedwOq8cht9E+bXKg/AzCEprP316QFDL48alsp/r5zZnBMnJTaC5645qs1+7dIsBN0jxH2K2xPo7qCGThIdfhCmoV6mR30Exph5wLxW6+7yWzbAz52/LpOdnU1ubi6FhQc53WJP4vXYWbvCImyF722y3XJXCEpDbXZP/zQOACGl1mZbvokoaSJ72R/s+gMlY+sKg/ZTcfhX1t09SKdFTh9bEXm9hgaPtzk88dEvtvP4lzs4cVQ6GfFRNHq8rMkrb042tq2wip8+t4L6Jg9XPrGYBo+Xsyb059zJWVz71FJ+8/Z6ThmTwdbCarYXVbcJYxzTP4Hh6XF8uKGABduKiI0IZVS2ddS5voJ+iVGkxUUyKTuRWUPbH+h2xoSWdvnLZw8ir7Q24L5D0+MYmu44P5tNQ+23ZNuLvxcRjh95EI7FsP2bpQ4rmgX10OgRRHfCL9JXHPol7ADh4eEMGXIAB1Jf8+oP7aTiLulj7HSLxgnB++EX8O49LSd9ccmZDVe9Z6eTbCiz63pCCPaH+08loTZfUbee2980ZCuiv36wiReX5PLhTScQGxnGqlw7mG1NXjknj47i8S+387t5G7hgygD+cvEk5q3eS22jh3duPI4z/m6f4bRByZw2NpOnrpqJMTYK5daXV7O9qLo574s/A1NjKKpq4MP1+5gxJIVwx2lbRwQivnj2V398TKfC08+c0I7Dts1zcAew9UEF1gEROmwI7VkfQUc5nExDmnSuN1j5vBWBmddaJ27OLDs/gPGLwy7bZefoDeSs7e/kRolOtqYlOHAOnu4mvAdbWS1MQzF4vYaXl+aSX1HHfxfspMnjZe0eKwSrc20o5kcb7JCTV5bnsaO4hsU7ShmZGceY/gk8ePlUIsNCOGl0BiLCcSPSOX5kOmGhIUzKsSahfgHC/9x49b3lddbE4lTMdSactLhImwoZ2yrvERNkTz7jA+GK0JFkGurjHkGzs7gDg+76miOiR3BI0FANq1+CkXPbhi++fxdkz4TTfwfTrrBx/+vfbLlP6U47o9jEi+1cAGBb38bjyxQaEgLRKdbH0Fc9gp6IzfZrhZZ7wtiyu4w9zhD+Bz/dyqh+cdQ1WtH858ebWbarlK+3lTB+QAJr8irIK61l2c5SznFCNueO78/6e/oFNKO4Q/xzUgIIQYovGueiadmOgz6EOiIC9iC6nebKuA/MM+57PRJMQ26PoI99BNojCDY8TXYy9zdvsFM3+tNUb5PGjTjVmlQyx9pKvHUytT3LrfM4c4LtNYRF+QZ3uT0C8E0icwQJQT0+p+v8TRW8viKPiNAQnrpqJh6v4conlgB2dGqjxzRPF/gtx3H88cZ9VNY3MWOwL6KnPVv6+AGJPPODWc357v0ZlBbj7JNgZ7USoWb85XzmndipEbFdJrwHxfZAiNh3fBB5lQ4ZengcQUeJaR5HcOi3t1UIuoOaIjsvANj5d9//FeTayqvFZCv++I8YjE6GXXb6PxKy7OTqblbQkHDrT3CJ6SMhaE7A1rlKasXuMjbmt8ylVFHX2CLPz7I9vmRpC3bV8Pzi3Zw9qT8Ts5P417enMmFAIlMHJnHTaSNJj4/k9jNGM3VgEuc6oZLvrLYzlHU0odfRw9MID5CLPiEqnBeuPYrn/aJtor9xP0vCpjbnyulRmsNH+6gyjojr9oFkfUIPjyPoKMPS40iLi2gx5eWhyqEvVYcDNSW+5b2rbF5/47GJ09wc+60rbrdlDzbe353cPWGAndDcPWd4TMsftHvc/uby7Qm62Mo6/wE7q9maX5/OWyv3EBoizHNSIbz70+MprKznwS/zcKvesKhY6mu8XHWs9ZUcPzK9RTTMuZOyEBGuPWEYAKmxEewpryM2IpSc5IO3b88c0jJdR0iI8NRVswKakrqdid+y77evHLYX/7f9FCOHE6GHho9g7vh+7U6HeaihQtAduCGfselWBPzXVTpzCbSuuN2WfUS8dR43C0EWHPuz9q+VMtQmVutt84HbSu2E3XVPmS9k8vZXVvPe2nwSosKorGuivsnL9c8uZ+G2YuqavHjDQgnBw6XHjKKfdwTjsgIn22rtpO2fFEVxdQMj+8V3KLVxV5g2qIOpgw+WlCGQ0o3pvTvL4GP67trdiX/eJKVDqGmoO6h1Wu/9/Gz5bsrmqvaEIAUQ+zlgql0nob4pBtvjhF/ADz482BJ3nk70CBZsLeazTYUs2m6fy+yhKby5cg8NTV6Kqhqob/IyfkACH6wvIDs5hg9+dgIhEVZopgzN4uentjO6OQBu8q9R7aVSUIKP5t+qCkFH0R5BV6grhwdmwwUPwZDjfK3/fhNgq1NJN/cICgBpm0UwJNT6BmJSof8ku098f7t+f4RH901kRwAfwSvLcpmUk2TTIzhsLqjku48tpNHjS/nx3ytn8Zu31xEiwhNf7UAEnr5qVvPIXBGx522o6vS9ZTnRPJ3NhqkcwTSbhlQIOor2CLpCyTao3AP5q+x3157vH93jCkFVvhWBQIOw4jLttsh4SB9tJ4fpRbYVVjHjtx+wdGfpgXdu1SOoa/Tw8xdWMucvnzbv4vEabn15FbGRYdx1tp2DaHJOEhFhIdxz3njuPncck3KSGJdlo3JE/OLxuxg62d/J36NCoDQTEWtNqO3lzVLaoD2CruBO0OKaf2pLneie0b59akvh8bPsBPH9JgQ+zzl/8+VWP++BHplNaX98uH4fhZX1/L+31vHqj4/e/yCpsJY9gt0lvukz//TeBuaMyWR1bjnLdpVx38WTuGBqNseNSCM+qmXExL++PRWvN0CCwC7Gsc8emsr4AQlMGBDYp6AEISGhcMPyvi7FYYUKQVdw7f5uq7+2xNr6/ad4rNoHlTassd05AQbO9i1nT+v2Yh6IhduLEbEhnkt2ljJjcIAJblxa2V23F1U3b3rg4628vmIPpdUNHD8ynW84WTVHBLDbuxk4256/a0nPJuck8db1x3XqGEVRWqKmoa7gjg2oLYX6Smsaik628+ee94AdPezOHQA2W+ghhsdrWLi9pDmVspuGuV2afQRRfLxxX7M56da5o7nupOHkltZigN+eP75r6RcOkItfUZSeQ3sEXcENCS3bCb93JpQZeLT9nHK5M5eAQ/YMOOmO3i1fB1iTV05lXROnjMlk+a4yquqa9n+A0xOo9oTy/cftvEFJMeH86MRhGGOoafAwbVByc+rlTnMkpUFWlMMM7RF0BXeQWMFa37ro5MDLFz0Ow07unXIdgN0lNfzo6aWs31vBE1/tICYilLOczJhV9QcSAttS31nu6+lkO6NtRYS7zhnb/rSIHSEsyqblDj30R2EqypGGCkFXcHsEjT6HaUAhkBDfJNSHAP/5bCvvrMnn/Ae+5I2Ve7h05sDm1AmthWBfRR1T7pnfnL7BNd1sKWkkPNSafvaW1dFthEVpb0BR+ggVgq7g9gj8afDLp+MKQXxW9+fu7yLV9U28tnwPc0ZncPH0HI4ZnsY1xw8lPDSEyLAQqlsJwSvL8yitaeSP723klPs+5fW1duK47WVNfP8Ym/7hymO7cQ6IsEj1DyhKH3Fo1FKHE8a0IwS+KJpmIWg9IX0f8sKS3VTVN/Hjk4a3SZkQFxlGpZ8QfLi+gOcW7SI6PLQ5OuiXb+7jvCgY0i+FU04Zwa1zRxPanSkdMsbagXqKovQ6KgSdpbbUpotOzLETycSkwuwfwfiLfPs0C0HvDRDbsq+K99bm8+MThyEiGGMorKonIz6KukYP//pkK7OHpgTMmxMXFdbcI9hUUMlVT9rMqb+/YAKbC6o4YVQ6D3+2jUXRP+Ocud9FeiKt7gm3dP85FUXpECoEncUdRZw6zApBQhYc36oSi4i1YpA2qteK9a9PtvDKsjzOmtCfrKRobnt5Fa+uyOMnJw6nqr6Jwsp6HrhsasBjYyN8QrB+r50B7L9XzuS4EWnNoaAnjEwH2pnYXlGUwxoVgs7S6JiAXLNPfFbbfUTg2s/a5hfqIZo83uapG+97fxPz1+VT1+hlysAk/vnxFgC+d9SgNimWXeKcjKAAmwuqCA0RZg1N6ZnpGBVFOeRQIegsDU6kUIJj9mlvgpikgb1THmDJzlLKauzYhTdW7mFAUjS//cZ4ThyVwdKdJSzcXtKc3z8QcZFh7Ku0EUCb91UyKDWGyLBDf3o9RVG6B40a6gw7vrAjicGahPw/+5BPNhYSHirNLf7LZg3kxFE2nfW0QSn8+MTh+63Y4yLDmgeUbS6oYmSGJnBTlGCiR4VAROaKyEYR2SIitwXYfoWIFIrICuevD2flaEV5Htw/1c44BrDlA3jiLPjiPvs9dbidVKa9hHI9RG5pDe+uyafR46W4qp6ymgYWbS9mYnYSp43NJCI0hAumds5JHRsZRlW9h7pGDzuKqxmZGXfggxRFOWLoMdOQiIQCDwCnArnAYhF5wxizrtWuzxtjruupcnSZ3EVQshXeuB6u/dQ3B3HZbvsZ1w9+sbVTM3Z1B//32ho+3lhIiIDXQGJ0ODUNTVx17FC+d/RgzpzQv3mylo4SFxlKUVU9Z/79c7wGJjn5hxRFCQ560kcwE9hijNkGICLPAecBrYXg0EScztLeFbbyL3USx0XE+D57eeKLfZV1fLa5iFPGZDIiM47YiFD+PH8TADOHJBMeGkJWe9k990NcpE3rsK2omnvOG8fJow8wS5qiKEcUPSkEA4Ddft9zCRx/eKGIHA9sAn5mjNndegcRuQa4BmDgwF5ywvoPEPv7JF820eoi+9kH6RDeWLEHj9dw2xmjGZ5hzTdr8iqYvy6faYP2k0L6AMRG+vwH500eoNFCihJk9LWz+E1gsDFmIvA+8GSgnYwxDxljphtjpqen905IZrMQXP5KyzBQd37iPhCCTzcVMiozvlkEAH53wYQW0z52hfgoX3vgYM6jKMrhSU/2CPIAv5layHbWNWOMKfb7+gjwxx4sT+doqLKfg46GkafDMj+NCgmDsJ73DTy7aBd7ymoZkRnP2rxylu0s5cJpLdNWpMRGcPTwtIO6Tmyk/Rn0SzjwxPSKohx59KQQLAZGiMgQrABcAlzmv4OI9DfGOOktORdY34Pl6RwN1dZPEBYFJ94G+athzzK7rYd7A59vLqS6volHPt9GXlktwzPiWJNnR/xO398sYl0k1kkZkZWkQqAowUiPCYExpklErgPeA0KBx4wxa0XkHmCJMeYN4AYRORdoAkqAK3qqPJ2modrOJyxixwpc8zH862jYt7ZHhcDjNfzipVWU1TRS22j9Eq4IAMzsASGoabDXGZQa2+3nVhTl0KdHRxYbY+YB81qtu8tv+Xbg9p4sQ5dpqLI5g/yJdGzzET0nBJ9tLmRveds8/6My4wkNEfoldn+rfc6YDC6dOZCbTxvZ7edWFOXQR1NMtEdDdVshiHCEoJt7BL9/x1rERmbEc9/7m0iJjSA6PJSq+ibiIsPIK6vlmatnkRzTM36JqPBQfn9B7w6MUxTl0EGFoD0CCoHzvRuFYF9lHY98vh2P1wAwMTuRW04fRZPXUF7TyNKdpazOKyc1rnfHLCiKEjyoELSH6yPwJ9LJwdONM2m9uiwPj9cwMTuRmIhQnvj+TKLCfXH9Z0/sj6MRiqIoPYIKQXs0VLVNI+0KQ+ueQid5d00+S3eWcPq4fry1ai9TBybx8o+OBmgzmCsstK+HeiiKcqSjQtAeDdWQPLjlOtdZfBA9gucW7eK2V1YDsHhHKRvyK7jq2KE6mldRlD5DhaA9esBH0NDk5bdvr+foYakMS4/jqa9t/qLxAxIOpqSKoigHhdodWlOxF/73TajIa+sjiHB8BF0wDZXXNPLlliIq65u46tghLWYLG5eVeDAlVhRFOSi0R9CaHV/A5vl2ub1xBJ00DeWV1XL2/Z9T6swidszwNIqrGwA7KcyglN7PW6QoiuKiQtCacr/kp+2OI+hcj+CmF1ZQ3+QF7CTwUeGhZCVGkZkQyaCUWEJC1D+gKErfoULQmvJc33Ib05DrI+h4j2BncTVfbyvhjjNHM2dMJqmxdlCYiPDXiycTF6WvQFGUvkVrodbsTwjccQSdSDExf20BAGeM709OKxPQwWYNVRRF6Q7UWdyaCr9M2a0r/Egnuqe1QLTDp5sKeX7Jbsb2T2gjAoqiKIcKKgSt8fcR1Fe13JY+Cs74I4w644CneX1FHt97bBE7i6u5bFYvzaqmKIrSBdQ05E9dBdSVQ84s2L0QUoe33C4Cs6494Gm+3lbMLS+uYtaQFJ68smXKCEVRlEMNFQJ/XLPQzGvgkmcgtuM2fGMMzy7aTVFVPQ99to2BqTE89J3pKgKKohzyqBD4U7DWfiYN7JQIAHyyqZA7XrWpI6YNSuafl00hMUbn/1UU5dBHhcDF64HP/mTNQVlTO3Xomyv38Jf5GxmUGsOzV8+mX0KUjg1QFOWwQZ3FLkseg8INcPKdENpxfdxbXsv1zy6nusHD774xgaykaBUBRVEOKzokBCLyioicJSJHpnCU7oT5/wfD5sDY8zt16Mrd5QA89J1pHKPjAhRFOQzpaMX+L+AyYLOI3Csio3qwTL3PrgXQVAun/cZGBnWCNXnlhIUIY/prBlFFUQ5POmQDMcZ8AHwgIonApc7ybuBh4GljTGMPlrHnqSmxnwn9O3zI7pIarnpyMZsKqhjTP0GjgxRFOWzpsKlHRFKBK4AfAMuBvwNTgfd7pGS9SW0pIBDZsXTQxhhufnElmwrsgLPs5O6bulJRFKW36aiP4FXgcyAGOMcYc64x5nljzPVAx/ItHMrUlkJ0EoR0TBc3FlSycHtJ84jhMyf068HCKYqi9Cwd7RHcb4wZa4z5vTFmr/8GY8z09g4SkbkislFEtojIbfvZ70IRMSLS7rl6lNpSiE7u8O7r91YA8L2jBrP+nrmcP3lAT5VMURSlx+moEIwVkST3i4gki8iP93eAiIQCDwBnAGOBS0VkbID94oEbgYUdLXS302khqCQiNISh6bFER4TqfMOKohzWdFQIrjbGlLlfjDGlwNUHOGYmsMUYs80Y0wA8B5wXYL//B/wBqOtgWbqfDgqBx2t48qsdLNhazIjMOMJDj8xoWkVRgouO1mSh4tfsdVr7EQc4ZgDgl8qTXGddMyIyFcgxxry9vxOJyDUiskRElhQWFnawyJ2gg0Lw/roCfvXGWlbnlWu4qKIoRwwdFYJ3gedFZI6IzAGeddZ1GWdw2n3ATQfa1xjzkDFmujFmenp6+sFcNjC1JRCdcsDdXlji07WcZJ1fQFGUI4OO5lK4FbgW+JHz/X3gkQMckwfk+H3Pdta5xAPjgU+czkY/4A0ROdcYs6SD5Tp4vB6bevoAPYL88jo+2biPa48fSlpcJBdOy+6lAiqKovQsHR1Q5gX+7fx1lMXACBEZghWAS7Cjk91zlgPNORlE5BPg5l4VAbAiAAcUgpeX5eI1cNmsgQxK7dzk9YqiKIcyHRICERkB/B4b/RPlrjfGDG3vGGNMk4hcB7wHhAKPGWPWisg9wBJjzBsHVfLuorbUfu5HCLxew/OLdzN7aIqKgKIoRxwdNQ09DvwK+CtwEvB9OuBfMMbMA+a1WndXO/ue2MGydC8dEIJ1eyvYVVLDDXNG9FKhFEVReo+OOoujjTEfAmKM2WmMuRs4q+eK1Yt0UAjATjijKIpypNHRHkG9E+Wz2TH35HEkpJaADgnBpvxKosJDGJiikUKKohx5dLRHcCM2z9ANwDTgcuB7PVWoXsXNPLofIdhYUMmIjHhCdcIZRVGOQA7YI3AGj33LGHMzUIX1Dxw5NPcIktrdZUN+JceP6IHxC4qiKIcAHXH4eoBje6EsfUNtKUQlQkjg+QRKqhsorKxndL/4Xi6YoihK79BRH8FyEXkDeBGodlcaY17pkVL1JvtJL1HX6OH6Z5cBMFUdxYqiHKF0VAiigGLgZL91BjiiheD9dQV8uaWY335jvEYMKYpyxNLRkcVHll/An/0IwYfrC0iJjeCSGQN7uVCKoii9R0dHFj+O7QG0wBhzZbeXqLepLYXkQW1WN3m8fLKpkJNHZ2i0kKIoRzQdNQ295bccBXwD2NP9xekDaksC9gi+3FpMWU0jp4zJ7INCKYqi9B4dNQ297P9dRJ4FvuiREvUmXi/UlrURgoKKOv750Wb6JUQxZ0xG35RNURSll+hoj6A1I4DDv4asLwdMi7kIlu4s5cJ/fwXA3eeMJTIscFipoijKkUJHfQSVtPQR5GPnKDi8CZBeYkO+zSt0w8nDuWxWW9+BoijKkUZHTUNH5miqAEKQW1pLeKhw4ykj1UmsKEpQ0KFcQyLyDRFJ9PueJCLn91ipeosAQrC7pIaspGgVAUVRgoaOJp37lTOjGADGmDLs/ASHN9XF9rNVjyA7ObqPCqQoitL7dFQIAu3XVUfzocPuryEiDpIHN6/KLa0lO0nTTSuKEjx0VAiWiMh9IjLM+bsPWNqTBesVtn4EQ46HsAjA5hYqqqonJ0V7BIqiBA8dFYLrgQbgeeA5oA74SU8Vqlco3gqlO2CYL31SbmkNANnJ2iNQFCV46GjUUDVwWw+XpXfZaccKMOSE5lVr99jQUe0RKIoSTHQ0auh9EUny+54sIu/1WKl6g/Jc++n4Bzxewz8/2sLQtFgmZSf1WbEURVF6m46ahtKcSCEAjDGlHO4jiyv3QGx6s3/gs82FbN5Xxc9OHUlYaEcfi6IoyuFPR2s8r4g052IWkcEEyEZ6WFGxFxKymr9uzK8E4PiROiWloijBRUeF4JfAFyLylIg8DXwK3H6gg0RkrohsFJEtItLGxyAiPxSR1SKyQkS+EJGxnSv+QVC5F+J9QrC9sJq0uAgSo8N7rQiKoiiHAh0SAmPMu8B0YCPwLHATULu/Y5xJ7x8AzgDGApcGqOifMcZMMMZMBv4I3Nep0h8MFXsgoX/z1+1F1QxNi+u1yyuKohwqdDTp3A+AG4FsYAUwG1hAy6krWzMT2GKM2eac4zngPGCdu4MxpsJv/1h6y9zUWGfnIfDrEWwrqmbO6MPb7aEoitIVOmoauhGYAew0xpwETAHKDnDMAGC33/dcZ10LROQnIrIV2yO4oYPlOTgq99pPp0dQUddIUVU9Q9Jje+XyiqIohxIdFYI6Y0wdgIhEGmM2AKO6owDGmAeMMcOwaa3vDLSPiFwjIktEZElhYeHBX9QVgngrBDuKqgEYkqZCoChK8NFRIch1xhG8BrwvIq8DOw9wTB6Q4/c921nXHs8B5wfaYIx5yBgz3RgzPT29G6J6KpxZNp2ooa2FVQAMVSFQFCUI6ejI4m84i3eLyMdAIvDuAQ5bDIwQkSFYAbgEuMx/BxEZYYzZ7Hw9C9hMb1BdZD9jrU9gU0EV4aHCYBUCRVGCkE5nEDXGfNrB/ZpE5DrgPSAUeMwYs1ZE7gGWGGPeAK4TkVOARqAU+F5ny9Ml6u2YASLtfDubC6oYkhZLuA4kUxQlCOnRVNLGmHnAvFbr7vJbvrEnr98u9RUQFtU8qnjzvkrGZyUe4CBFUZQjk+BsAtdXQGQCALUNHnaV1DAiU8cQKIoSnASpEFQ2m4W2FlZhDIzMPDKnZVYURTkQQS8EW/bZiKERGdojUBQlOAl6IdheVI0IDEzVyWgURQlOglMI6iogyjqHdxZXk5UYTWRYaB8XSlEUpW8ITiHw6xHsKK5hcJr2BhRFCV6CVAgq/ISgmkGpOpBMUZTgJfiEwBinR5BAWU0DZTWNDFEhUBQliAk+IWisAeOByHh2FtcAMEgdxYqiBDHBJwR+6SV2FNuso2oaUhQlmAliIUhgc0EVoSGizmJFUYKa4BOCOmdStKgENhVUMig1RkNHFUUJaoJPCOodIYiMZ/O+KkZmaGoJRVGCmyAUAmsaqg+NZWdxNSM12ZyiKEFO0ArBzqoQvAZG9tMegaIowU3wCUFtKQCbK+xUDCPUNKQoSpATfEJQuRfCotlSbh3EOoZAUZRgJ/iEoCIPErLYXVZLZkIkUeEaMaQoSnAThEKw1wpBSQ05ydobUBRFCUIh2AMJWeSW1pKTokKgKIoSXELg9ULlXjxx/dlbXktOcnRfl0hRFKXPCS4hqCkCbyPlYWl4DWRrj0BRFCXIhKBiDwD5pAKoj0BRFIUgFYLcpiQAstU0pCiK0rNCICJzRWSjiGwRkdsCbP+5iKwTkVUi8qGIDOrJ8lBphWC3IwQZCZE9ejlFUZTDgR4TAhEJBR4AzgDGApeKyNhWuy0HphtjJgIvAX/sqfIAzZlHc+siSYoJ16yjiqIo9GyPYCawxRizzRjTADwHnOe/gzHmY2NMjfP1ayC7B8sDTXUA7K0ypMdpb0BRFAV6VggGALv9vuc669rjKuCdQBtE5BoRWSIiSwoLC7teosZaCIumsLqB9HgVAkVRFDhEnMUicjkwHfhToO3GmIeMMdONMdPT09O7fqHGWgiPorCyXoVAURTFIawHz50H5Ph9z3bWtUBETgF+CZxgjKnvwfJAUy2Ex1BYWq+mIUVRFIee7BEsBkaIyBARiQAuAd7w30FEpgD/Ac41xuzrwbJYGmvxhkZR2+ghTXsEiqIoQA8KgTGmCbgOeA9YD7xgjFkrIveIyLnObn8C4oAXRWSFiLzRzum6h8Y6mkKsAGiPQFEUxdKTpiGMMfOAea3W3eW3fEpPXr8NjTU0uEKgPQJFURTgEHEW9xpNddQRAagQKIqiuASXEDTWNgtBalxEHxdGURTl0CD4hMBYAUiMDu/jwiiKohwaBJcQNNVSSwQRYSGaXkJRFMUhuISgsZYaE0FCVI/6yBVFUQ4rgkwI6qjxhhMXqUKgKIriElxC0FRLlSec+Cj1DyiKorgEjxB4GsHb5AiB9ggURVFcgkcIGmsBqPSEqWlIURTFj6ATgvImNQ0piqL4EzxC0OQKQaiahhRFUfwIHiFwegRljWEaPqooiuJH0AlBrQknToVAURSlmeARAme+4joi1EegKIriR/AIQWMNALUmUn0EiqIofgSRENgeQT0RGj6qKIriRxAJgeMjUNOQoihKC4JHCJzw0TpNOqcoitKC4BGCRp+zWKOGFEVRfASREDjOYvURKIqitCB4asTxF/DKnmTqlkUQGxE8t60oinIggqdHkDSQdTEziI4IJyRE+ro0iqIohwzBIwRAdYOHWDULKYqitKBHhUBE5orIRhHZIiK3Bdh+vIgsE5EmEbmoJ8sCUF3fRGyEzlWsKIriT48JgYiEAg8AZwBjgUtFZGyr3XYBVwDP9FQ5/Kmub9IegaIoSit6slacCWwxxmwDEJHngPOAde4OxpgdzjZvD5ajmeoGFQJFUZTW9KRpaACw2+97rrOu04jINSKyRESWFBYWdrlA1fUeNQ0piqK04rBwFhtjHjLGTDfGTE9PT+/yedQ0pCiK0paeFII8IMfve7azrs+obmjSwWSKoiit6EkhWAyMEJEhIhIBXAK80YPXOyDV9R5idDCZoihKC3pMCIwxTcB1wHvAeuAFY8xaEblHRM4FEJEZIpILfBP4j4is7cHyOD0C9REoiqL406PNY2PMPGBeq3V3+S0vxpqMepzaRg/GoD4CRVGUVhwWzuLuoKq+CYAYFQJFUZQWBI0QVNd7ANQ0pCiK0oogEgLbI9DMo4qiKC0JPiFQ05CiKEoLgkcIGlQIFEVRAhE8QqA+AkVRlIAEkRA4UUPqI1AURWlB0AhBlfoIFEVRAhI0QjAwJYa54/pp9lFFUZRWBE3z+LRx/ThtXL++LoaiKMohR9D0CBRFUZTAqBAoiqIEOSoEiqIoQY4KgaIoSpCjQqAoihLkqBAoiqIEOSoEiqIoQY4KgaIoSpAjxpi+LkOnEJFCYGcXD08DirqxOH2J3suhid7LoYneCwwyxqQH2nDYCcHBICJLjDHT+7oc3YHey6GJ3suhid7L/lHTkKIoSpCjQqAoihLkBJsQPNTXBehG9F4OTfReDk30XvZDUPkIFEVRlLYEW49AURRFaYUKgaIoSpATNEIgInNFZKOIbBGR2/q6PJ1FRHaIyGoRWSEiS5x1KSLyvohsdj6T+7qcgRCRx0Rkn4is8VsXsOxiud95T6tEZGrflbwt7dzL3SKS57ybFSJypt+225172Sgip/dNqdsiIjki8rGIrBORtSJyo7P+sHsv+7mXw/G9RInIIhFZ6dzLr531Q0RkoVPm50Ukwlkf6Xzf4mwf3KULG2OO+D8gFNgKDAUigJXA2L4uVyfvYQeQ1mrdH4HbnOXbgD/0dTnbKfvxwFRgzYHKDpwJvAMIMBtY2Nfl78C93A3cHGDfsc5vLRIY4vwGQ/v6Hpyy9QemOsvxwCanvIfde9nPvRyO70WAOGc5HFjoPO8XgEuc9Q8CP3KWfww86CxfAjzflesGS49gJrDFGLPNGNMAPAec18dl6g7OA550lp8Ezu+7orSPMeYzoKTV6vbKfh7wX2P5GkgSkf69UtAO0M69tMd5wHPGmHpjzHZgC/a32OcYY/YaY5Y5y5XAemAAh+F72c+9tMeh/F6MMabK+Rru/BngZOAlZ33r9+K+r5eAOSIinb1usAjBAGC33/dc9v9DORQxwHwRWSoi1zjrMo0xe53lfCCzb4rWJdor++H6rq5zTCaP+ZnoDot7ccwJU7Ctz8P6vbS6FzgM34uIhIrICmAf8D62x1JmjGlydvEvb/O9ONvLgdTOXjNYhOBI4FhjzFTgDOAnInK8/0Zj+4aHZSzw4Vx2h38Dw4DJwF7gL31amk4gInHAy8BPjTEV/tsOt/cS4F4Oy/dijPEYYyYD2dieyuievmawCEEekOP3PdtZd9hgjMlzPvcBr2J/IAVu99z53Nd3Jew07ZX9sHtXxpgC55/XCzyMz8xwSN+LiIRjK87/GWNecVYflu8l0L0cru/FxRhTBnwMHIU1xYU5m/zL23wvzvZEoLiz1woWIVgMjHA87xFYp8obfVymDiMisSIS7y4DpwFrsPfwPWe37wGv900Ju0R7ZX8D+K4TpTIbKPczVRyStLKVfwP7bsDeyyVOZMcQYASwqLfLFwjHjvwosN4Yc5/fpsPuvbR3L4fpe0kXkSRnORo4Fevz+Bi4yNmt9Xtx39dFwEdOT65z9LWXvLf+sFEPm7D2tl/2dXk6Wfah2CiHlcBat/xYW+CHwGbgAyClr8vaTvmfxXbNG7H2zavaKzs2auIB5z2tBqb3dfk7cC9POWVd5fxj9vfb/5fOvWwEzujr8vuV61is2WcVsML5O/NwfC/7uZfD8b1MBJY7ZV4D3OWsH4oVqy3Ai0Cksz7K+b7F2T60K9fVFBOKoihBTrCYhhRFUZR2UCFQFEUJclQIFEVRghwVAkVRlCBHhUBRFCXIUSFQlF5ERE4Ukbf6uhyK4o8KgaIoSpCjQqAoARCRy5288CtE5D9OIrAqEfmrkyf+QxFJd/adLCJfO8nNXvXL4T9cRD5wcssvE5FhzunjROQlEdkgIv/rSrZIRelOVAgUpRUiMgb4FnCMscm/PMC3gVhgiTFmHPAp8CvnkP8CtxpjJmJHsrrr/wc8YIyZBByNHZEMNjvmT7F58YcCx/TwLSnKfgk78C6KEnTMAaYBi53GejQ2+ZoXeN7Z52ngFRFJBJKMMZ86658EXnRyQw0wxrwKYIypA3DOt8gYk+t8XwEMBr7o8btSlHZQIVCUtgjwpDHm9hYrRf6v1X5dzc9S77fsQf8PlT5GTUOK0pYPgYtEJAOa5/EdhP1/cTNAXgZ8YYwpB0pF5Dhn/XeAT42dKStXRM53zhEpIjG9eROK0lG0JaIorTDGrBORO7EzwoVgM43+BKgGZjrb9mH9CGDTAD/oVPTbgO87678D/EdE7nHO8c1evA1F6TCafVRROoiIVBlj4vq6HIrS3ahpSFEUJcjRHoGiKEqQoz0CRVGUIEeFQFEUJchRIVAURQlyVAgURVGCHBUCRVGUIOf/AyGkH7v4OBMtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0414 - accuracy: 0.5486\n",
      "Test accuracy: 54.86%\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_best_only=True, save_weights_only=True, verbose=1, monitor=\"val_accuracy\"\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.20,\n",
    "        epochs=300,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path, ModelName):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path),20)\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "\n",
    "    #if dequence model has been trained then use it otherwise load model\n",
    "    try:\n",
    "        model = sequence_model\n",
    "        print(\"Using trained model\")\n",
    "    except NameError:\n",
    "        model = get_sequence_model()\n",
    "        model.load_weights(\"tmp/Models/\" + ModelName + \"/video_classifier\")\n",
    "        \n",
    "    probabilities = model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: C:/Users/bencl/Desktop/data/Test/K282.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bencl\\AppData\\Local\\Temp/ipykernel_15032/3488690343.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return np.array([np.array(cv2.resize(imageio.imread(video_file), resize)) for i in range(3)])\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bencl\\AppData\\Local\\Temp/ipykernel_15032/1144576727.py\", line 24, in sequence_prediction\n",
      "    model = sequence_model\n",
      "NameError: name 'sequence_model' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Local\\Temp/ipykernel_15032/2590638761.py\", line 7, in <module>\n",
      "    test_frames = sequence_prediction(test_dir + test_video, ModelName)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Local\\Temp/ipykernel_15032/1144576727.py\", line 28, in sequence_prediction\n",
      "    model.load_weights(\"tmp/Models/\" + ModelName + \"/video_classifier\")\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2331, in load_weights\n",
      "    status = self._trackable_saver.restore(filepath, options)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\", line 1382, in restore\n",
      "    base.CheckpointPosition(\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 254, in restore\n",
      "    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 980, in _restore_from_checkpoint_position\n",
      "    current_position.checkpoint.restore_saveables(\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\", line 351, in restore_saveables\n",
      "    new_restore_ops = functional_saver.MultiDeviceSaver(\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\", line 339, in restore\n",
      "    restore_ops = restore_fn()\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\", line 323, in restore_fn\n",
      "    restore_ops.update(saver.restore(file_prefix, options))\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\", line 115, in restore\n",
      "    restore_ops[saveable.name] = saveable.restore(\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\", line 131, in restore\n",
      "    return resource_variable_ops.shape_safe_assign_variable_handle(\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 309, in shape_safe_assign_variable_handle\n",
      "    shape.assert_is_compatible_with(value_tensor.shape)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 1161, in assert_is_compatible_with\n",
      "    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n",
      "ValueError: Shapes (36,) and (26,) are incompatible\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\bencl\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\Program Files\\Python39\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\Program Files\\Python39\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\Program Files\\Python39\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\Program Files\\Python39\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"c:\\Program Files\\Python39\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15032/1144576727.py\u001b[0m in \u001b[0;36msequence_prediction\u001b[1;34m(path, ModelName)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using trained model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sequence_model' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15032/2590638761.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test video path: {test_dir + test_video}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#to_gif(test_frames[:MAX_SEQ_LENGTH])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15032/1144576727.py\u001b[0m in \u001b[0;36msequence_prediction\u001b[1;34m(path, ModelName)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sequence_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tmp/Models/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mModelName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/video_classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         options=options)\n\u001b[1;32m-> 1382\u001b[1;33m     base.CheckpointPosition(\n\u001b[0m\u001b[0;32m   1383\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    979\u001b[0m     restore_ops.extend(\n\u001b[1;32m--> 980\u001b[1;33m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[0;32m    981\u001b[0m             tensor_saveables, python_saveables))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    350\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m--> 351\u001b[1;33m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0m\u001b[0;32m    352\u001b[0m           validated_saveables).restore(self.save_path_tensor, self.options)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m           \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[1;32m--> 115\u001b[1;33m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0m\u001b[0;32m    116\u001b[0m           restored_tensors, restored_shapes=None)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    130\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0m\u001b[0;32m    132\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m   \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m   return gen_resource_variable_ops.assign_variable_op(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (36,) and (26,) are incompatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ValueError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "test_dir = \"C:/Users/bencl/Desktop/data/Test/\"\n",
    "ModelName = \"Alphabet and Numbers 65%\" \n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_dir + test_video}\")\n",
    "test_frames = sequence_prediction(test_dir + test_video, ModelName)\n",
    "#to_gif(test_frames[:MAX_SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A: 100.00% seconds elapsed: 2.3245651721954346, requested at: 21:01:18, current time: 21:01:20\n",
      "  A: 100.00% seconds elapsed: 2.0678117275238037, requested at: 21:01:20, current time: 21:01:22\n",
      "  J: 98.55% seconds elapsed: 2.207491159439087, requested at: 21:01:23, current time: 21:01:25\n",
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#get live feed from web cam and predict the action given last 10 frames\n",
    "import cv2\n",
    "\n",
    "MODEL_NAME = \"Alphabet Only 55 epochs 83.599%\"\n",
    "\n",
    "MODEL_DIR = \"tmp/Models/\" + MODEL_NAME + \"/video_classifier\"\n",
    "\n",
    "def predict_signs():\n",
    "    try:\n",
    "        model = sequence_model\n",
    "    except NameError:\n",
    "        model = get_sequence_model()\n",
    "        model.load_weights(MODEL_DIR)\n",
    "        \n",
    "    current_frames = []\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #check if opened correctly\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            flags, frame = cap.read()\n",
    "            if not flags:\n",
    "                print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "                break\n",
    "            cv2.imshow('img', frame)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            current_frames.append(frame)\n",
    "            if len(current_frames) == 10:\n",
    "                #get current time in seconds\n",
    "                start = time.time()\n",
    "                #convert start to time in hours and minutes\n",
    "                start_time = time.strftime(\"%H:%M:%S\", time.gmtime(start))\n",
    "                #turn frames into video with cv2 \n",
    "                frame_features, frame_mask = prepare_single_video(load_video(current_frames, 20))\n",
    "                probabilities = model.predict([frame_features, frame_mask])[0]\n",
    "                class_vocab = label_processor.get_vocabulary()\n",
    "                i = np.argsort(probabilities)[::-1][0]\n",
    "                if(probabilities[i] > 0.75):\n",
    "                    time_now = time.strftime(\"%H:%M:%S\", time.gmtime(time.time()))\n",
    "                    print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}% seconds elapsed: {time.time() - start}, requested at: {start_time}, current time: {time_now}\")\n",
    "\n",
    "                current_frames = []\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows() \n",
    "\n",
    "predict_signs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
